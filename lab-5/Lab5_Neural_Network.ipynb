{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lab5_Neural_Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A2iZtzneOaHB"
      },
      "source": [
        "# Введение. Нейронные сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "10XVW4CV_583"
      },
      "source": [
        "В машинном обучении особое место занимают нейронные сети. Как можно догадаться из названия, нейронная сеть была создана на основе нейронов в мозгу человека.\n",
        "\n",
        "Нейронные сети хорошо себя зарекомендовали в анализе изображений, так называемое компьютерное зрение. Они хороши в:\n",
        "* Классификации - отделении среди всех картинок заранее распределенных групп, например, деление на кошек и собак.\n",
        "* Предсказание — возможность предсказывать следующий шаг. Например, рост или падение акций, основываясь на ситуации на фондовом рынке.\n",
        "* Распознавание — самым простым примером является распознавание вашего лица камерой телефона.\n",
        "\n",
        "Нейронные сети имеют свои плюсы:\n",
        "1. Устойчивость к шумам входных данных\n",
        "2. Адаптация к изменениям при обучении\n",
        "3. Быстродействие\n",
        "\n",
        "Однако нейронные сети редко дают точные ответы и являются лишь дополнением к решениям человека. Например, в медицине нейронные сети используются для анализа медицинских изображений, однако чаще всего не дают точного диагноза, а всего лишь предсказывают вероятность того или иного заболевания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ftdfx4fAOrfH"
      },
      "source": [
        "## Строение нейронной сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0JPJH7_cOnf0"
      },
      "source": [
        "Нейрон похож на функцию: он принимает на вход несколько значений и возвращает одно. Важно помнить, что нейроны оперируют числами в диапазоне [0,1] или [-1,1], а числа, выходящие за этот диапозон, необходимо нормализовать.\n",
        "\n",
        "\n",
        "Ниже представлена схема работы искуссвенного нейрона.\n",
        "\n",
        "У нейрона есть $n$ входов $x_i$, у каждого из которого есть вес $w_i$, на который умножается сигнал, проходящий по связи. После этого взвешенные сигналы $x_i*w_i$ направляются в сумматор, который аггрегирует все сигналы во взвешенную сумму. Эту сумму также называют net. Таким образом, $\n",
        "net=\\sum\\limits_{i=1}^n w_i*x_i$.\n",
        "\n",
        "Далее к полученной сумме применяют функцию активации, которая преобразует взвешенную сумму в какое-то число, которое и будет являться выходом нейрона. Функция активации обозначается ϕ(net). Таким образом, выходов искусственного нейрона является ϕ(net)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w41MClSEBfyw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "d2f072e6-520e-44f2-aede-4a0493910f68"
      },
      "source": [
        "from IPython.display import Image \n",
        "from IPython.core.display import HTML \n",
        "Image(url= \"http://neerc.ifmo.ru/wiki/images/a/a5/Искусственный_нейрон_схема.png\", width=500)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"http://neerc.ifmo.ru/wiki/images/a/a5/Искусственный_нейрон_схема.png\" width=\"500\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YSwfESIXD0Va"
      },
      "source": [
        "Если вы объедините эти нейроны, то получите прямо распространяющуюся нейронную сеть — процесс идёт от ввода к выводу, через нейроны, соединённые связями с значениями весов (синапсами). От веса зависит степень важности признака $x_i$, которая меняется в процессе обучения. Во время инициализации нейронной сети, веса расставляются в случайном порядке. \n",
        "\n",
        "Для обучения сети в прямо распространяющейся нейронной сети вы проходите все нейроны до выходного слоя, а затем сеть подстраивает веса $w_i$ с помощью метода обратного распространения ошибки.\n",
        "\n",
        "В нейронной сети есть два обязательных слоя: входной и выходной, а слои посередине называются скрытыми.\n",
        "\n",
        "Количество нейронов в выходном слое зависит от задачи. Например, в случае классификации количество выходных нейронов равно тому количеству классов, на которые делится выборка изображений."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TJgYXRz0Eamw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "7a6a8902-b117-4938-bbec-208dc2b696c5"
      },
      "source": [
        "Image(url= \"https://cdn.tproger.ru/wp-content/uploads/2016/08/15GSpUs2hWFx4Lq2_KCyulg.png\", width=400)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://cdn.tproger.ru/wp-content/uploads/2016/08/15GSpUs2hWFx4Lq2_KCyulg.png\" width=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OOj4HJ7wOxMc"
      },
      "source": [
        "## Функции активации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5E7OS9lQEZoi"
      },
      "source": [
        "Поговорим о функциях активации. По сути, это всего лишь некоторая функция, которая применяется к после сумматора, для получения нужного ответа. Их много, например, Линейная, Сигмоид (Логистическая),Гиперболический тангенс. В данной лабораторной мы применим две функции, ReLU(Rectified linear unit) и Softmax, однако подробно рассматривать их не будем.\n",
        "\n",
        "В случае ReLU $f(x) = max(0,x)$. Пользуясь определением, становится понятно, что ReLu возвращает значение х, если х положительно, и 0 в противном случае.\n",
        "\n",
        "Функция Softmax применяется в машинном обучении для задач классификации, когда количество возможных классов больше двух, и обычно на выходном слое. Сумма всех выходных сигналов при этом равна 1 (то есть каждое значение это вероятность принадлежности данного изображения к классу).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bIGgVnxsO2Fw"
      },
      "source": [
        "## Валидационная выборка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9udJxPxlbNKu"
      },
      "source": [
        "Отметим еще один важный момент. В прошлых лабораторных мы делили наш датсет на обучающую и тестовую выборку. Однако сегодя мы рассмотрим еще одну выборку, на которую можно делить датасет. Это так называемая валидационная выборка (validation или иногда development set).\n",
        "\n",
        "Тогда датасет делится на:\n",
        "* Обучающую выборку, на которой запускается алгоритм обучения;\n",
        "* Валидационную, которая используется для настройки параметров, выбора признаков и принятия других решений относительно алгоритма обучения, иногда такую выборку называют удерживаемой для перёкрестной проверки (hold-out cross validation set);\n",
        "* Тестовую, на которой оценивают качество работы алгоритма, но на её основе не принимают никаких решений о том, какой алгоритм обучения или параметры использовать."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "evxybmNGFQEQ"
      },
      "source": [
        "#Основные шаги по выполнению лабораторной работы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iQb3o1jPFTng"
      },
      "source": [
        "##1. Импортируем необходимые библиотеки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8neiwUyZFWZW"
      },
      "source": [
        "В данной лабораторной работе мы будем использовать библиотеку Tensorflow. TensorFlow — открытая программная библиотека для машинного обучения, разработанная компанией Google для решения задач построения и тренировки нейронной сети с целью автоматического нахождения и классификации образов, достигая качества человеческого восприятия.\n",
        "\n",
        "Для работы с сетями глубокого обучения мы будем использовать нейросетевую библиотеку Keras, являющуюся надстройкой над Tensorflow.\n",
        "\n",
        "В Keras уже есть встроенные датасеты, например, fashion_mnist и мы воспользуемся им для построения нейронной сети. Также нам понабится уже знакомая библиотека numpy и matplotlib для отрисовки графиков.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_tTKGRkNFONo",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "%matplotlib inline "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HKiRH_t2JtqS"
      },
      "source": [
        "##2. Подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ObOlKtkeKinJ"
      },
      "source": [
        "Мы будем работать с датасетом fashion_mnist, представляющим собой набор картинок одежды, обуви или сумок.\n",
        "\n",
        "Разделим датасет на обучающую и тестовую выборки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BjRkgMf2FPnl",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test,y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LlvdbHNxK5Qj"
      },
      "source": [
        "И создадим список с названиями классов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sL2U3wZ0FPqG",
        "colab": {}
      },
      "source": [
        "classes = ['футболка', 'брюки', 'свитер', 'платье', 'пальто', 'туфли', 'рубашка', 'кроссовки', 'сумка', 'ботинки']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vATjYUHbLICC"
      },
      "source": [
        "Так как мы работаем с изображениями, а не с числами, следует понять, как они представлены в компьютере. Наши изображения на самом деле являются набором точек разного цвета. Более научно - двумерными массивами, содрежащими числа, которые харктеризуют интенсивность пикселя для черно-белого изображения. В таком случае значение 0 будет значить черный пиксель, а 255 белый. Позже мы нормализуем эти значения, чтобы они были от нуля до единицы.\n",
        "\n",
        "Посмотрим картинки из нашего набора данных:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pX_znbkmFPuc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "f2e5fa40-0c4c-4cf3-dbe1-ee8915fe3a97"
      },
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "for i in range(1,21):\n",
        "    plt.subplot(2,10,i)\n",
        "    plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(classes[y_train[i]])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABH4AAAEiCAYAAACPwRUyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1440x360 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JV3JryIHP7uZ"
      },
      "source": [
        "Нейронная сеть принимает на вход плоский вектор, а не двумерные изображения, которые имеются в fashion_mnist. Так что мы преобразуем размерность наших данных:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2GEKQprAFPsr",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(60000, 784) # 60000 изображений по 784 пикселя в каждом\n",
        "X_test = X_test.reshape(10000, 784)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QIDYux3QQjdt"
      },
      "source": [
        "Дальше мы нормализуем данные. Нормализация данных необходима, чтобы в своих результатах не зависить от величин переменных, а только от их соотношения. Здесь мы используем деление на 255 для приведения значения пикселей в диапозон от 0 до 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h_rDkFMYQiI3",
        "colab": {}
      },
      "source": [
        "X_train = X_train / 255 \n",
        "X_test = X_test / 255 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xDSm-IVvSPUb"
      },
      "source": [
        "Входные данные мы подготовили, теперь давайте поговорим о выходных. Наша задача, чтобы при подачи картинки в нейронную сеть, она смогла сказать нам, является ли эта вещь футболкой, обувью, сумкой и т.д. Предсказания нашей нейронной сети записаны с помощью списка из 10 классов, где все значения равны 0, кроме предсказанного класса, равного 1. Это называется подход one hot encoding.\n",
        "\n",
        "То есть если картинка была определена как футболка (1 в списке classes), то программа выдаст [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]. \n",
        "\n",
        "А если как рубашка (7 в списке classes), то [0, 0, 0, 0, 0, 0, 1, 0, 0, 0].\n",
        "\n",
        "С помощью следующего кода мы превратим наш y_train и y_test в такие же массивы, понятные нейронной сети. И сравним y_train до и после.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S_r6mzBbUOYY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8382e28d-0403-4b1c-cd1a-e392f0b6945c"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j_4FRqlcT1cy",
        "colab": {}
      },
      "source": [
        "y_train = utils.to_categorical(y_train, 10)\n",
        "y_test = utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JcOwwstIUSNO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6097dbe0-8604-4473-d9c4-715c46b71e06"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5sNbnaQbQiNJ"
      },
      "source": [
        "##3. Создание нейронной сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "023je-szUopy"
      },
      "source": [
        "При создании нейронной сети мы будем использовать модель Sequental из библиотеки Keras, в которой все слои сети идут последовательно друг за другом.\n",
        "\n",
        "Объявим модель:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kcLk57ZwUoDo",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A6LS-RR5VJta"
      },
      "source": [
        "И создадим два полносвязных слоя: входной и выходной.\n",
        "\n",
        "Входным слоем является тот, который принимает наши данные. Зададим здесь количество нейронов (800), количество пикселей (784 или для сети 784 входа в каждый нейрон) и активационную функцию (ReLU).\n",
        "\n",
        "На выходном слое мы укажем количество классов, которые получатся при предсказании (10) и и активационную функцию (Softmax)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ftqdx3k1VHBk",
        "colab": {}
      },
      "source": [
        "model.add(Dense(800, input_dim=784, activation=\"relu\"))\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YtJfveCuWGKZ"
      },
      "source": [
        "Далее мы скомпилируем нашу модель и посмотрим на ее описание.\n",
        "\n",
        "Здесь мы используем функцию ошибки категориальная перекрестная энтропия (вместо метода наименьших квадратов),  стохастический градиентный спуск (SGD) в качестве оптимизатора и точность в метрике."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6AANUJwEWB6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c914575a-ae92-48b8-8029-4ffb5b647b37"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 800)               628000    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                8010      \n",
            "=================================================================\n",
            "Total params: 636,010\n",
            "Trainable params: 636,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bBjf-3CfW0kG"
      },
      "source": [
        "##4. Обучение нейронной сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SGgNQW0NWpbC"
      },
      "source": [
        "Теперь обучим сети с помощью метода fit. Здесь же мы задаем некоторые параметры при обучении:\n",
        "\n",
        "* batch_size - размер мини-выборки для стохастического градиентного спуска. Мы берем batch_size изображений, прогоняем через сеть, меняем веса и повторяем процедуру.\n",
        "* epochs - количество эпох, то есть сколько раз мы будем обучаться на полном наборе данных\n",
        "* validation_split - деление нашей обучающей выборки на обучающую и валидационную\n",
        "* verbose - отвечает за подробность изображения отчета при обучении (0, 1 или 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nLi9LtW6YfsO"
      },
      "source": [
        "В выводе обучения мы можем увидеть информацию по каждой эпохе: количество использованных изображений, время выполнения, функция ошибки и точность (доля правильных ответов), а также последние два параметра для валидационной выборки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OkRDwJvHWooq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "09813b2e-c6d8-495a-daf3-4cf47e6d8bf7"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=200, epochs=100, validation_split=0.2, verbose=1)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/100\n",
            "48000/48000 [==============================] - 1s 30us/sample - loss: 1.1940 - acc: 0.6527 - val_loss: 0.8384 - val_acc: 0.7442\n",
            "Epoch 2/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.7634 - acc: 0.7632 - val_loss: 0.6953 - val_acc: 0.7771\n",
            "Epoch 3/100\n",
            "48000/48000 [==============================] - 1s 28us/sample - loss: 0.6652 - acc: 0.7906 - val_loss: 0.6325 - val_acc: 0.7978\n",
            "Epoch 4/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.6128 - acc: 0.8076 - val_loss: 0.5919 - val_acc: 0.8081\n",
            "Epoch 5/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.5782 - acc: 0.8149 - val_loss: 0.5631 - val_acc: 0.8162\n",
            "Epoch 6/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.5533 - acc: 0.8217 - val_loss: 0.5433 - val_acc: 0.8200\n",
            "Epoch 7/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.5344 - acc: 0.8264 - val_loss: 0.5276 - val_acc: 0.8252\n",
            "Epoch 8/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.5188 - acc: 0.8304 - val_loss: 0.5159 - val_acc: 0.8282\n",
            "Epoch 9/100\n",
            "48000/48000 [==============================] - 1s 25us/sample - loss: 0.5062 - acc: 0.8323 - val_loss: 0.5067 - val_acc: 0.8298\n",
            "Epoch 10/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.4956 - acc: 0.8357 - val_loss: 0.4959 - val_acc: 0.8310\n",
            "Epoch 11/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.4862 - acc: 0.8383 - val_loss: 0.4899 - val_acc: 0.8313\n",
            "Epoch 12/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.4787 - acc: 0.8403 - val_loss: 0.4828 - val_acc: 0.8347\n",
            "Epoch 13/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.4715 - acc: 0.8420 - val_loss: 0.4734 - val_acc: 0.8385\n",
            "Epoch 14/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.4651 - acc: 0.8450 - val_loss: 0.4679 - val_acc: 0.8396\n",
            "Epoch 15/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.4590 - acc: 0.8466 - val_loss: 0.4646 - val_acc: 0.8407\n",
            "Epoch 16/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.4537 - acc: 0.8473 - val_loss: 0.4607 - val_acc: 0.8432\n",
            "Epoch 17/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.4491 - acc: 0.8487 - val_loss: 0.4560 - val_acc: 0.8440\n",
            "Epoch 18/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.4444 - acc: 0.8496 - val_loss: 0.4509 - val_acc: 0.8460\n",
            "Epoch 19/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.4398 - acc: 0.8517 - val_loss: 0.4480 - val_acc: 0.8457\n",
            "Epoch 20/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.4363 - acc: 0.8523 - val_loss: 0.4480 - val_acc: 0.8463\n",
            "Epoch 21/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.4322 - acc: 0.8549 - val_loss: 0.4394 - val_acc: 0.8508\n",
            "Epoch 22/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.4292 - acc: 0.8549 - val_loss: 0.4368 - val_acc: 0.8507\n",
            "Epoch 23/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.4256 - acc: 0.8560 - val_loss: 0.4350 - val_acc: 0.8511\n",
            "Epoch 24/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.4224 - acc: 0.8568 - val_loss: 0.4309 - val_acc: 0.8522\n",
            "Epoch 25/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.4194 - acc: 0.8577 - val_loss: 0.4287 - val_acc: 0.8530\n",
            "Epoch 26/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.4160 - acc: 0.8588 - val_loss: 0.4259 - val_acc: 0.8538\n",
            "Epoch 27/100\n",
            "48000/48000 [==============================] - 1s 28us/sample - loss: 0.4138 - acc: 0.8597 - val_loss: 0.4262 - val_acc: 0.8533\n",
            "Epoch 28/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.4111 - acc: 0.8605 - val_loss: 0.4226 - val_acc: 0.8551\n",
            "Epoch 29/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.4087 - acc: 0.8611 - val_loss: 0.4224 - val_acc: 0.8553\n",
            "Epoch 30/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.4061 - acc: 0.8619 - val_loss: 0.4173 - val_acc: 0.8571\n",
            "Epoch 31/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.4038 - acc: 0.8633 - val_loss: 0.4161 - val_acc: 0.8562\n",
            "Epoch 32/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.4013 - acc: 0.8635 - val_loss: 0.4147 - val_acc: 0.8573\n",
            "Epoch 33/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3993 - acc: 0.8632 - val_loss: 0.4126 - val_acc: 0.8579\n",
            "Epoch 34/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3973 - acc: 0.8646 - val_loss: 0.4101 - val_acc: 0.8588\n",
            "Epoch 35/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3953 - acc: 0.8647 - val_loss: 0.4091 - val_acc: 0.8576\n",
            "Epoch 36/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3929 - acc: 0.8661 - val_loss: 0.4071 - val_acc: 0.8589\n",
            "Epoch 37/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3910 - acc: 0.8661 - val_loss: 0.4058 - val_acc: 0.8612\n",
            "Epoch 38/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3891 - acc: 0.8671 - val_loss: 0.4050 - val_acc: 0.8608\n",
            "Epoch 39/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3872 - acc: 0.8681 - val_loss: 0.4024 - val_acc: 0.8607\n",
            "Epoch 40/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3856 - acc: 0.8680 - val_loss: 0.4024 - val_acc: 0.8614\n",
            "Epoch 41/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3836 - acc: 0.8686 - val_loss: 0.3993 - val_acc: 0.8626\n",
            "Epoch 42/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3820 - acc: 0.8691 - val_loss: 0.4035 - val_acc: 0.8598\n",
            "Epoch 43/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3807 - acc: 0.8702 - val_loss: 0.3970 - val_acc: 0.8628\n",
            "Epoch 44/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3786 - acc: 0.8705 - val_loss: 0.3955 - val_acc: 0.8629\n",
            "Epoch 45/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3770 - acc: 0.8714 - val_loss: 0.3943 - val_acc: 0.8649\n",
            "Epoch 46/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3756 - acc: 0.8711 - val_loss: 0.3944 - val_acc: 0.8642\n",
            "Epoch 47/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3740 - acc: 0.8716 - val_loss: 0.3955 - val_acc: 0.8641\n",
            "Epoch 48/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3720 - acc: 0.8730 - val_loss: 0.3928 - val_acc: 0.8638\n",
            "Epoch 49/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3709 - acc: 0.8729 - val_loss: 0.3907 - val_acc: 0.8632\n",
            "Epoch 50/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3694 - acc: 0.8730 - val_loss: 0.3916 - val_acc: 0.8647\n",
            "Epoch 51/100\n",
            "48000/48000 [==============================] - 1s 28us/sample - loss: 0.3682 - acc: 0.8737 - val_loss: 0.3902 - val_acc: 0.8652\n",
            "Epoch 52/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3666 - acc: 0.8738 - val_loss: 0.3878 - val_acc: 0.8658\n",
            "Epoch 53/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3656 - acc: 0.8746 - val_loss: 0.3854 - val_acc: 0.8664\n",
            "Epoch 54/100\n",
            "48000/48000 [==============================] - 1s 29us/sample - loss: 0.3642 - acc: 0.8751 - val_loss: 0.3861 - val_acc: 0.8664\n",
            "Epoch 55/100\n",
            "48000/48000 [==============================] - 1s 29us/sample - loss: 0.3629 - acc: 0.8755 - val_loss: 0.3864 - val_acc: 0.8667\n",
            "Epoch 56/100\n",
            "48000/48000 [==============================] - 1s 29us/sample - loss: 0.3611 - acc: 0.8767 - val_loss: 0.3878 - val_acc: 0.8658\n",
            "Epoch 57/100\n",
            "48000/48000 [==============================] - 1s 28us/sample - loss: 0.3602 - acc: 0.8763 - val_loss: 0.3814 - val_acc: 0.8682\n",
            "Epoch 58/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3590 - acc: 0.8762 - val_loss: 0.3843 - val_acc: 0.8657\n",
            "Epoch 59/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3576 - acc: 0.8769 - val_loss: 0.3797 - val_acc: 0.8681\n",
            "Epoch 60/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3562 - acc: 0.8778 - val_loss: 0.3819 - val_acc: 0.8663\n",
            "Epoch 61/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3551 - acc: 0.8783 - val_loss: 0.3807 - val_acc: 0.8662\n",
            "Epoch 62/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3540 - acc: 0.8785 - val_loss: 0.3793 - val_acc: 0.8683\n",
            "Epoch 63/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3526 - acc: 0.8785 - val_loss: 0.3776 - val_acc: 0.8693\n",
            "Epoch 64/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3514 - acc: 0.8791 - val_loss: 0.3795 - val_acc: 0.8687\n",
            "Epoch 65/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3506 - acc: 0.8794 - val_loss: 0.3755 - val_acc: 0.8690\n",
            "Epoch 66/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3489 - acc: 0.8798 - val_loss: 0.3771 - val_acc: 0.8684\n",
            "Epoch 67/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3479 - acc: 0.8798 - val_loss: 0.3740 - val_acc: 0.8697\n",
            "Epoch 68/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3472 - acc: 0.8808 - val_loss: 0.3739 - val_acc: 0.8687\n",
            "Epoch 69/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3463 - acc: 0.8804 - val_loss: 0.3727 - val_acc: 0.8687\n",
            "Epoch 70/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3447 - acc: 0.8810 - val_loss: 0.3730 - val_acc: 0.8684\n",
            "Epoch 71/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3438 - acc: 0.8810 - val_loss: 0.3708 - val_acc: 0.8707\n",
            "Epoch 72/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3424 - acc: 0.8821 - val_loss: 0.3716 - val_acc: 0.8704\n",
            "Epoch 73/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3417 - acc: 0.8816 - val_loss: 0.3734 - val_acc: 0.8704\n",
            "Epoch 74/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3403 - acc: 0.8830 - val_loss: 0.3686 - val_acc: 0.8702\n",
            "Epoch 75/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3400 - acc: 0.8823 - val_loss: 0.3681 - val_acc: 0.8717\n",
            "Epoch 76/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3389 - acc: 0.8832 - val_loss: 0.3678 - val_acc: 0.8712\n",
            "Epoch 77/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3375 - acc: 0.8832 - val_loss: 0.3683 - val_acc: 0.8706\n",
            "Epoch 78/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3368 - acc: 0.8835 - val_loss: 0.3667 - val_acc: 0.8722\n",
            "Epoch 79/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3356 - acc: 0.8837 - val_loss: 0.3652 - val_acc: 0.8715\n",
            "Epoch 80/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3350 - acc: 0.8843 - val_loss: 0.3656 - val_acc: 0.8716\n",
            "Epoch 81/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3339 - acc: 0.8851 - val_loss: 0.3642 - val_acc: 0.8723\n",
            "Epoch 82/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3330 - acc: 0.8856 - val_loss: 0.3685 - val_acc: 0.8717\n",
            "Epoch 83/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3324 - acc: 0.8851 - val_loss: 0.3653 - val_acc: 0.8709\n",
            "Epoch 84/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3312 - acc: 0.8852 - val_loss: 0.3639 - val_acc: 0.8723\n",
            "Epoch 85/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3303 - acc: 0.8852 - val_loss: 0.3616 - val_acc: 0.8732\n",
            "Epoch 86/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3294 - acc: 0.8861 - val_loss: 0.3619 - val_acc: 0.8723\n",
            "Epoch 87/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3283 - acc: 0.8871 - val_loss: 0.3627 - val_acc: 0.8715\n",
            "Epoch 88/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3270 - acc: 0.8864 - val_loss: 0.3624 - val_acc: 0.8712\n",
            "Epoch 89/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3264 - acc: 0.8867 - val_loss: 0.3635 - val_acc: 0.8708\n",
            "Epoch 90/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3260 - acc: 0.8867 - val_loss: 0.3605 - val_acc: 0.8727\n",
            "Epoch 91/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3250 - acc: 0.8871 - val_loss: 0.3583 - val_acc: 0.8748\n",
            "Epoch 92/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3237 - acc: 0.8879 - val_loss: 0.3612 - val_acc: 0.8722\n",
            "Epoch 93/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3234 - acc: 0.8876 - val_loss: 0.3593 - val_acc: 0.8735\n",
            "Epoch 94/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3223 - acc: 0.8876 - val_loss: 0.3570 - val_acc: 0.8741\n",
            "Epoch 95/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3214 - acc: 0.8876 - val_loss: 0.3583 - val_acc: 0.8753\n",
            "Epoch 96/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3211 - acc: 0.8880 - val_loss: 0.3560 - val_acc: 0.8758\n",
            "Epoch 97/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3201 - acc: 0.8892 - val_loss: 0.3583 - val_acc: 0.8761\n",
            "Epoch 98/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3190 - acc: 0.8897 - val_loss: 0.3615 - val_acc: 0.8730\n",
            "Epoch 99/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3183 - acc: 0.8892 - val_loss: 0.3547 - val_acc: 0.8743\n",
            "Epoch 100/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3175 - acc: 0.8891 - val_loss: 0.3550 - val_acc: 0.8754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0b91b0b6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HZR-U1N9YSX6"
      },
      "source": [
        "Обученную сеть так же можно сохранить для дальнейшего использоавния, чтобы не тратить постоянно время на обучение:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GeB94cATYOkf",
        "colab": {}
      },
      "source": [
        "model.save('fashion_mnist_dense.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ER29tMRhlo4G"
      },
      "source": [
        "Тогда загрузить ее можно таким образом:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xEfWfgmZloAT",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "new_model = load_model('fashion_mnist_dense.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cHYnggDncQvG"
      },
      "source": [
        "##5. Оценка качества обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EeH_1NRCccNo"
      },
      "source": [
        "Для начала посмотрим на значения val_acc  в выводе выше. Можно заметить, что в начале обучения точность растет, но к концу начинает то подниматься, то опускаться (97-100 эпохи).  Это один из явных признаков переобучения.\n",
        "Еще если val_loss ошибка увеличивается, а loss уменьшается, это также говорит о переобучении.\n",
        "\n",
        "Также давайте используем наш тестовый датасет для предсказания и выведем точность (здесь выводится самый простой вариант определения точности, однако не самый лучший):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vcoe-sH0c7ze",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3163f788-2a4e-4f1e-903e-7cffd7ebf7ac"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 79us/sample - loss: 0.3791 - acc: 0.8665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sHDNtw9dc7zk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83c1030a-b835-4744-93ef-edb872e92285"
      },
      "source": [
        "print(\"Доля верных ответов на тестовых данных, в процентах:\", round(scores[1] * 100, 4))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля верных ответов на тестовых данных, в процентах: 86.65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HNENk4h2ey6E"
      },
      "source": [
        "Вы можете загружать собственные картинки в нейронную сеть, но посмотрим для примера распознавание одной картинки из тестового датасета (например 354ой):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oIRuV6oue46F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a735b16a-c075-47b3-81fb-2e5e4edac839"
      },
      "source": [
        "plt.imshow(X_test[354].reshape(28, 28), cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ia6eAU5eh7yY"
      },
      "source": [
        "Предскажем класс изображения, передав в predict 354ую картинку из тестового набора X, с преобразованной размерностью (np.expand_dims)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IkzQLU2Pe46L",
        "colab": {}
      },
      "source": [
        "prediction = model.predict(np.expand_dims(X_test[354], axis=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QEWSpvTve46M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d9d3073b-c2ec-4b02-b4a4-25d7abeb9a72"
      },
      "source": [
        "prediction"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.5555759e-01, 3.0522147e-04, 1.4832080e-02, 1.4116846e-01,\n",
              "        3.3127155e-02, 6.6951480e-07, 6.5084672e-01, 2.4711373e-06,\n",
              "        4.1583139e-03, 1.2887119e-06]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cri8B428iRA2"
      },
      "source": [
        "Выведем предсказанный класс и реальный класс:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OATW0Iywe46N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3e9b850-74cb-4fa0-8027-ba14da7b0200"
      },
      "source": [
        "prediction = np.argmax(prediction[0])\n",
        "print(\"Это изображение предсказано как\", prediction, \"класс, то есть это\", classes[prediction])\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Это изображение предсказано как 6 класс, то есть это рубашка\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T_C0z-gEe46P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48beb09c-ed16-4130-f941-bdc65f7309ac"
      },
      "source": [
        "label = np.argmax(y_test[354])\n",
        "print(\"Это изображение является\", label, \"классом, то есть это\",  classes[label])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Это изображение является 6 классом, то есть это рубашка\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ea6MMwfvjL1V"
      },
      "source": [
        "##6. Увеличение качества обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bT-Bgoo5jMcO"
      },
      "source": [
        "Для увеличения точности работы нейронной сети можно изменять ее параметры.\n",
        "Основыными параметрами для изменения являются:\n",
        "1. Количество эпох обучения.\n",
        "2. Размер мини-выборки.\n",
        "3. Количество нейронов входного слоя.\n",
        "4. Наличие скрытых слоев."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "miZrDD9-jMcQ"
      },
      "source": [
        "### Количество эпох обучения и размер мини выборки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8EpNzxZ1jMcQ"
      },
      "source": [
        "Данные параметры задаются при обучении модели.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Wlm-41hjMcR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74a3b86a-88a0-4d4f-a0ca-c9e673c1ed01"
      },
      "source": [
        "history = model.fit(X_train, y_train, \n",
        "                    batch_size=200,        # Размер мини-выборки\n",
        "                    epochs=100,            # Количество эпох\n",
        "                    validation_split=0.2, \n",
        "                    verbose=1)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3165 - acc: 0.8901 - val_loss: 0.3573 - val_acc: 0.8739\n",
            "Epoch 2/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3160 - acc: 0.8900 - val_loss: 0.3551 - val_acc: 0.8759\n",
            "Epoch 3/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3149 - acc: 0.8904 - val_loss: 0.3569 - val_acc: 0.8742\n",
            "Epoch 4/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3139 - acc: 0.8910 - val_loss: 0.3518 - val_acc: 0.8768\n",
            "Epoch 5/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3133 - acc: 0.8917 - val_loss: 0.3580 - val_acc: 0.8744\n",
            "Epoch 6/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3124 - acc: 0.8916 - val_loss: 0.3519 - val_acc: 0.8778\n",
            "Epoch 7/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3117 - acc: 0.8916 - val_loss: 0.3508 - val_acc: 0.8777\n",
            "Epoch 8/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3108 - acc: 0.8920 - val_loss: 0.3556 - val_acc: 0.8750\n",
            "Epoch 9/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3105 - acc: 0.8915 - val_loss: 0.3526 - val_acc: 0.8783\n",
            "Epoch 10/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3096 - acc: 0.8918 - val_loss: 0.3505 - val_acc: 0.8771\n",
            "Epoch 11/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3089 - acc: 0.8934 - val_loss: 0.3496 - val_acc: 0.8767\n",
            "Epoch 12/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3080 - acc: 0.8924 - val_loss: 0.3524 - val_acc: 0.8755\n",
            "Epoch 13/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3070 - acc: 0.8937 - val_loss: 0.3496 - val_acc: 0.8779\n",
            "Epoch 14/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3067 - acc: 0.8931 - val_loss: 0.3485 - val_acc: 0.8763\n",
            "Epoch 15/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3055 - acc: 0.8946 - val_loss: 0.3485 - val_acc: 0.8772\n",
            "Epoch 16/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3050 - acc: 0.8935 - val_loss: 0.3459 - val_acc: 0.8772\n",
            "Epoch 17/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3045 - acc: 0.8938 - val_loss: 0.3468 - val_acc: 0.8783\n",
            "Epoch 18/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3038 - acc: 0.8949 - val_loss: 0.3451 - val_acc: 0.8784\n",
            "Epoch 19/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3030 - acc: 0.8950 - val_loss: 0.3461 - val_acc: 0.8787\n",
            "Epoch 20/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.3025 - acc: 0.8949 - val_loss: 0.3462 - val_acc: 0.8782\n",
            "Epoch 21/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3012 - acc: 0.8956 - val_loss: 0.3457 - val_acc: 0.8787\n",
            "Epoch 22/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3010 - acc: 0.8959 - val_loss: 0.3475 - val_acc: 0.8781\n",
            "Epoch 23/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.3004 - acc: 0.8960 - val_loss: 0.3445 - val_acc: 0.8789\n",
            "Epoch 24/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2996 - acc: 0.8958 - val_loss: 0.3441 - val_acc: 0.8783\n",
            "Epoch 25/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2988 - acc: 0.8963 - val_loss: 0.3443 - val_acc: 0.8783\n",
            "Epoch 26/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2976 - acc: 0.8972 - val_loss: 0.3439 - val_acc: 0.8782\n",
            "Epoch 27/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2974 - acc: 0.8965 - val_loss: 0.3463 - val_acc: 0.8777\n",
            "Epoch 28/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2969 - acc: 0.8964 - val_loss: 0.3458 - val_acc: 0.8786\n",
            "Epoch 29/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2960 - acc: 0.8969 - val_loss: 0.3435 - val_acc: 0.8789\n",
            "Epoch 30/100\n",
            "48000/48000 [==============================] - 1s 28us/sample - loss: 0.2952 - acc: 0.8978 - val_loss: 0.3423 - val_acc: 0.8792\n",
            "Epoch 31/100\n",
            "48000/48000 [==============================] - 1s 29us/sample - loss: 0.2945 - acc: 0.8980 - val_loss: 0.3442 - val_acc: 0.8778\n",
            "Epoch 32/100\n",
            "48000/48000 [==============================] - 1s 29us/sample - loss: 0.2940 - acc: 0.8979 - val_loss: 0.3409 - val_acc: 0.8791\n",
            "Epoch 33/100\n",
            "48000/48000 [==============================] - 1s 29us/sample - loss: 0.2935 - acc: 0.8982 - val_loss: 0.3402 - val_acc: 0.8817\n",
            "Epoch 34/100\n",
            "48000/48000 [==============================] - 1s 29us/sample - loss: 0.2928 - acc: 0.8986 - val_loss: 0.3400 - val_acc: 0.8799\n",
            "Epoch 35/100\n",
            "48000/48000 [==============================] - 1s 29us/sample - loss: 0.2918 - acc: 0.8985 - val_loss: 0.3423 - val_acc: 0.8796\n",
            "Epoch 36/100\n",
            "48000/48000 [==============================] - 1s 29us/sample - loss: 0.2910 - acc: 0.8994 - val_loss: 0.3439 - val_acc: 0.8795\n",
            "Epoch 37/100\n",
            "48000/48000 [==============================] - 1s 28us/sample - loss: 0.2907 - acc: 0.8991 - val_loss: 0.3394 - val_acc: 0.8803\n",
            "Epoch 38/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2897 - acc: 0.8998 - val_loss: 0.3425 - val_acc: 0.8800\n",
            "Epoch 39/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2894 - acc: 0.8994 - val_loss: 0.3380 - val_acc: 0.8817\n",
            "Epoch 40/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2887 - acc: 0.8999 - val_loss: 0.3382 - val_acc: 0.8812\n",
            "Epoch 41/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2884 - acc: 0.8991 - val_loss: 0.3389 - val_acc: 0.8798\n",
            "Epoch 42/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2874 - acc: 0.9003 - val_loss: 0.3400 - val_acc: 0.8801\n",
            "Epoch 43/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2866 - acc: 0.9010 - val_loss: 0.3367 - val_acc: 0.8826\n",
            "Epoch 44/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2860 - acc: 0.9013 - val_loss: 0.3369 - val_acc: 0.8827\n",
            "Epoch 45/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2859 - acc: 0.9006 - val_loss: 0.3389 - val_acc: 0.8793\n",
            "Epoch 46/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2849 - acc: 0.9020 - val_loss: 0.3384 - val_acc: 0.8803\n",
            "Epoch 47/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2841 - acc: 0.9012 - val_loss: 0.3371 - val_acc: 0.8811\n",
            "Epoch 48/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2840 - acc: 0.9013 - val_loss: 0.3365 - val_acc: 0.8823\n",
            "Epoch 49/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2833 - acc: 0.9012 - val_loss: 0.3362 - val_acc: 0.8807\n",
            "Epoch 50/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2825 - acc: 0.9020 - val_loss: 0.3413 - val_acc: 0.8800\n",
            "Epoch 51/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2819 - acc: 0.9015 - val_loss: 0.3355 - val_acc: 0.8833\n",
            "Epoch 52/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2811 - acc: 0.9020 - val_loss: 0.3337 - val_acc: 0.8835\n",
            "Epoch 53/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2806 - acc: 0.9038 - val_loss: 0.3368 - val_acc: 0.8803\n",
            "Epoch 54/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2806 - acc: 0.9034 - val_loss: 0.3344 - val_acc: 0.8826\n",
            "Epoch 55/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2791 - acc: 0.9031 - val_loss: 0.3364 - val_acc: 0.8829\n",
            "Epoch 56/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2793 - acc: 0.9031 - val_loss: 0.3334 - val_acc: 0.8842\n",
            "Epoch 57/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2780 - acc: 0.9032 - val_loss: 0.3322 - val_acc: 0.8821\n",
            "Epoch 58/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2774 - acc: 0.9036 - val_loss: 0.3328 - val_acc: 0.8838\n",
            "Epoch 59/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2774 - acc: 0.9045 - val_loss: 0.3333 - val_acc: 0.8824\n",
            "Epoch 60/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2768 - acc: 0.9038 - val_loss: 0.3337 - val_acc: 0.8836\n",
            "Epoch 61/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2762 - acc: 0.9040 - val_loss: 0.3322 - val_acc: 0.8830\n",
            "Epoch 62/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2757 - acc: 0.9042 - val_loss: 0.3359 - val_acc: 0.8818\n",
            "Epoch 63/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2747 - acc: 0.9046 - val_loss: 0.3311 - val_acc: 0.8832\n",
            "Epoch 64/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2744 - acc: 0.9046 - val_loss: 0.3318 - val_acc: 0.8836\n",
            "Epoch 65/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2735 - acc: 0.9054 - val_loss: 0.3304 - val_acc: 0.8845\n",
            "Epoch 66/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2733 - acc: 0.9047 - val_loss: 0.3357 - val_acc: 0.8812\n",
            "Epoch 67/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2728 - acc: 0.9051 - val_loss: 0.3320 - val_acc: 0.8826\n",
            "Epoch 68/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2717 - acc: 0.9057 - val_loss: 0.3317 - val_acc: 0.8836\n",
            "Epoch 69/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2713 - acc: 0.9054 - val_loss: 0.3392 - val_acc: 0.8805\n",
            "Epoch 70/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2715 - acc: 0.9065 - val_loss: 0.3311 - val_acc: 0.8823\n",
            "Epoch 71/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2699 - acc: 0.9064 - val_loss: 0.3358 - val_acc: 0.8822\n",
            "Epoch 72/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2700 - acc: 0.9065 - val_loss: 0.3290 - val_acc: 0.8842\n",
            "Epoch 73/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2694 - acc: 0.9071 - val_loss: 0.3304 - val_acc: 0.8841\n",
            "Epoch 74/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2689 - acc: 0.9060 - val_loss: 0.3287 - val_acc: 0.8827\n",
            "Epoch 75/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2682 - acc: 0.9069 - val_loss: 0.3287 - val_acc: 0.8838\n",
            "Epoch 76/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2673 - acc: 0.9076 - val_loss: 0.3294 - val_acc: 0.8850\n",
            "Epoch 77/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2673 - acc: 0.9069 - val_loss: 0.3273 - val_acc: 0.8854\n",
            "Epoch 78/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2663 - acc: 0.9078 - val_loss: 0.3284 - val_acc: 0.8842\n",
            "Epoch 79/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2657 - acc: 0.9075 - val_loss: 0.3265 - val_acc: 0.8850\n",
            "Epoch 80/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2651 - acc: 0.9081 - val_loss: 0.3268 - val_acc: 0.8852\n",
            "Epoch 81/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2650 - acc: 0.9085 - val_loss: 0.3269 - val_acc: 0.8851\n",
            "Epoch 82/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2642 - acc: 0.9081 - val_loss: 0.3280 - val_acc: 0.8853\n",
            "Epoch 83/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2632 - acc: 0.9089 - val_loss: 0.3289 - val_acc: 0.8848\n",
            "Epoch 84/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2631 - acc: 0.9090 - val_loss: 0.3264 - val_acc: 0.8849\n",
            "Epoch 85/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2624 - acc: 0.9092 - val_loss: 0.3271 - val_acc: 0.8855\n",
            "Epoch 86/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2622 - acc: 0.9093 - val_loss: 0.3312 - val_acc: 0.8822\n",
            "Epoch 87/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2615 - acc: 0.9099 - val_loss: 0.3252 - val_acc: 0.8850\n",
            "Epoch 88/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2609 - acc: 0.9100 - val_loss: 0.3305 - val_acc: 0.8839\n",
            "Epoch 89/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2602 - acc: 0.9106 - val_loss: 0.3288 - val_acc: 0.8841\n",
            "Epoch 90/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2600 - acc: 0.9106 - val_loss: 0.3300 - val_acc: 0.8838\n",
            "Epoch 91/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2593 - acc: 0.9109 - val_loss: 0.3265 - val_acc: 0.8837\n",
            "Epoch 92/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2594 - acc: 0.9111 - val_loss: 0.3246 - val_acc: 0.8857\n",
            "Epoch 93/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2584 - acc: 0.9111 - val_loss: 0.3271 - val_acc: 0.8841\n",
            "Epoch 94/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2577 - acc: 0.9115 - val_loss: 0.3252 - val_acc: 0.8852\n",
            "Epoch 95/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2578 - acc: 0.9114 - val_loss: 0.3247 - val_acc: 0.8840\n",
            "Epoch 96/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2570 - acc: 0.9115 - val_loss: 0.3259 - val_acc: 0.8846\n",
            "Epoch 97/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2561 - acc: 0.9118 - val_loss: 0.3232 - val_acc: 0.8863\n",
            "Epoch 98/100\n",
            "48000/48000 [==============================] - 1s 26us/sample - loss: 0.2562 - acc: 0.9110 - val_loss: 0.3233 - val_acc: 0.8847\n",
            "Epoch 99/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2559 - acc: 0.9116 - val_loss: 0.3240 - val_acc: 0.8859\n",
            "Epoch 100/100\n",
            "48000/48000 [==============================] - 1s 27us/sample - loss: 0.2548 - acc: 0.9121 - val_loss: 0.3230 - val_acc: 0.8860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nuULSuQ-jMcT"
      },
      "source": [
        "### Количество нейронов входного слоя"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uo8rAF2sjMcT"
      },
      "source": [
        "Количество нейронов задается при создании входного слоя. Здесь оно 200."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ju-o3QMCjMcU",
        "colab": {}
      },
      "source": [
        "model.add(Dense(200, input_dim=784, activation=\"relu\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yhzNeiBljMcV"
      },
      "source": [
        "### Наличие скрытых слоев"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VN7Pbrn3jMcW"
      },
      "source": [
        "Скрытыми слоями называются слои, находящиеся между входным и выходным. Они добавляются в последовательную модель, как и входной и выходной слой."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HYN8liRkjMcW",
        "colab": {}
      },
      "source": [
        "model.add(Dense(800, input_dim=784, activation=\"relu\"))\n",
        "model.add(Dense(600, activation=\"relu\"))  # Новый скрытый слой\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H2uGgoNcnThG"
      },
      "source": [
        "#Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jKjKpXAInYdZ"
      },
      "source": [
        "Возьмите созданную нейронную сеть, датасет fashion-mnist и попытайтесь улучшить точность обучения. Варианты для улучшения:\n",
        "1. Используйте разное количество нейронов на входном слое: 400, 600, 800, 1200.\n",
        "2. Добавьте в нейронную сеть скрытый слой с разным количеством нейронов: 200, 300, 400, 600, 800.\n",
        "3. Добавьте несколько скрытых слоев в сеть с разным количеством нейронов в каждом слое.\n",
        "4. Используйте разное количество эпох: 10, 15, 20, 25, 30.\n",
        "5. Используйте разные размеры мини-выборки (batch_size): 10, 50, 100, 200, 500.\n",
        "\n",
        "Опишите влияние (или его отсутствие) на точность работы вашей нейронной сети измененяемых параметров.\n",
        "\n",
        "Сохраните два варианта сети, при котором точность нейронной сети минимальна и максимальна, выведите точность и сделайте вывод о переобучении. Необходимо менять не менее трех параметров (то есть использовать не менее трех вариантов из списка выше). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l0UYIejx1XO",
        "colab_type": "text"
      },
      "source": [
        "# Выполнение задания\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yop1-t2Gu8oV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDCpRTUJoTXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "0aa4a9b8-2da9-4263-940f-300f7912ca4e"
      },
      "source": [
        "model.add(Dense(400, input_dim=784, activation=\"relu\"))   # 400 neurons\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, batch_size=10, epochs=10, validation_split=0.2, verbose=1) #batch_size=10 epochs=10"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/10\n",
            "48000/48000 [==============================] - 19s 386us/sample - loss: 0.6028 - acc: 0.7967 - val_loss: 0.4622 - val_acc: 0.8400\n",
            "Epoch 2/10\n",
            "48000/48000 [==============================] - 18s 385us/sample - loss: 0.4500 - acc: 0.8436 - val_loss: 0.4343 - val_acc: 0.8508\n",
            "Epoch 3/10\n",
            "48000/48000 [==============================] - 18s 382us/sample - loss: 0.4064 - acc: 0.8590 - val_loss: 0.3979 - val_acc: 0.8618\n",
            "Epoch 4/10\n",
            "48000/48000 [==============================] - 18s 384us/sample - loss: 0.3798 - acc: 0.8662 - val_loss: 0.4094 - val_acc: 0.8583\n",
            "Epoch 5/10\n",
            "48000/48000 [==============================] - 18s 383us/sample - loss: 0.3602 - acc: 0.8731 - val_loss: 0.3701 - val_acc: 0.8690\n",
            "Epoch 6/10\n",
            "48000/48000 [==============================] - 18s 383us/sample - loss: 0.3425 - acc: 0.8790 - val_loss: 0.3758 - val_acc: 0.8684\n",
            "Epoch 7/10\n",
            "48000/48000 [==============================] - 19s 390us/sample - loss: 0.3307 - acc: 0.8826 - val_loss: 0.3625 - val_acc: 0.8721\n",
            "Epoch 8/10\n",
            "48000/48000 [==============================] - 18s 382us/sample - loss: 0.3181 - acc: 0.8860 - val_loss: 0.3499 - val_acc: 0.8723\n",
            "Epoch 9/10\n",
            "48000/48000 [==============================] - 18s 385us/sample - loss: 0.3083 - acc: 0.8888 - val_loss: 0.3630 - val_acc: 0.8706\n",
            "Epoch 10/10\n",
            "48000/48000 [==============================] - 18s 384us/sample - loss: 0.2997 - acc: 0.8923 - val_loss: 0.3332 - val_acc: 0.8814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0b915d4550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVf4I_Q6oOkS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca20e7f6-c323-4ff9-d876-d7d9c7c5ea80"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 80us/sample - loss: 0.3566 - acc: 0.8714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0ufemFqwPyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"400n-10batch-10epoch.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnmSPFibwag-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af63361c-d8c0-4a9b-a693-449f408195ac"
      },
      "source": [
        "model = Sequential()  \n",
        "model.add(Dense(600, input_dim=784, activation=\"relu\"))   # 600 neurons\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, batch_size=50, epochs=15, validation_split=0.2, verbose=0) #batch=50;epochs=15\n",
        "scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "model.save(\"600n-50batch-15epoch.h5\")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 81us/sample - loss: 0.4157 - acc: 0.8552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1R6LWKcxIYy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34a63342-e5fe-4d96-f02b-960ef1fd006e"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(800, input_dim=784, activation=\"relu\"))   # 800 neurons\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, batch_size=100, epochs=20, validation_split=0.2, verbose=0) #batch=100;epochs=20\n",
        "scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "model.save(\"800n-100batch-20epochs.h5\")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 80us/sample - loss: 0.4350 - acc: 0.8488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzSaXowvxgVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb9a57d5-aae0-4305-cb4c-9fd1b2c33594"
      },
      "source": [
        "model = Sequential()  \n",
        "model.add(Dense(1200, input_dim=784, activation=\"relu\"))   # 1200 neurons\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, batch_size=200, epochs=100, validation_split=0.2, verbose=0) #batch=200;epochs=25\n",
        "scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "model.save(\"1200n-200batch-25epoch.h5\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 86us/sample - loss: 0.3766 - acc: 0.8692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S9vt9QU2gJM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ca2d12f-6ed1-488c-f1a0-e4258f5012b5"
      },
      "source": [
        "model = Sequential()  \n",
        "model.add(Dense(1200, input_dim=784, activation=\"relu\"))   # 1200 neurons\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, batch_size=200, epochs=100, validation_split=0.2, verbose=0) #batch=500;epochs=30\n",
        "scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "model.save(\"1200n-500batch-30epoch.h5\")"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 86us/sample - loss: 0.3761 - acc: 0.8673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh17bRvH3Oon",
        "colab_type": "text"
      },
      "source": [
        "Как вывод, получаем такой результат:\n",
        "<hr>\n",
        "\n",
        "| Neurons | batch_size | epochs | acc    |\n",
        "| ------- | ---------- | ------ | ------ |\n",
        "| 400     | 10         | 10     | 0.8714 |\n",
        "| 600     | 50         | 15     | 0.8552 |\n",
        "| 800     | 100        | 20     | 0.8488 |\n",
        "| 1200    | 200        | 25     | 0.8692 |\n",
        "| 1200    | 500        | 30     | 0.8673 |\n",
        "\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pByn3kgr5lL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}