{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab6_Transfer_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IXelAlZrGs0o"
      },
      "source": [
        "#Сверточные нейронные сети (Convolutional Neural Network, CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vpNGKmcJG27x"
      },
      "source": [
        "В прошлой работе мы разобрали структуру нейронной сети, а точнее прямо распространяющуюся нейронную сеть. В этот раз мы поговорим о другом типе нейронных сетей - сверточные. Возьмем двумерную сверточную сеть."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-UdI3DDOHvLZ"
      },
      "source": [
        "Сверточные сети построены на операции свертки.\n",
        "\n",
        "Имеется ядро – небольшая матрица весов. Это ядро «скользит» по двумерным входным данным, выполняя поэлементное умножение для той части данных, которую сейчас покрывает. Результаты перемножений ячеек суммируются в одном выходном пикселе. В случае сверточных нейросетей ядро определяется в ходе обучения сети. \n",
        "\n",
        "Перемножение и суммирование повторяются для каждой локации, по которой проходит ядро. Двумерная матрица входных признаков преобразуется в двумерную матрицу выходных. Выходные признаки, таким образом, являются взвешенными суммами входных признаков. Число входных признаков в комбинации для одного выходного признака определяет размер ядра."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zhxYG9QR2EqL"
      },
      "source": [
        "![convUrl](https://media.proglib.io/wp-uploads/2018/06/2.gif \"Convolution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WffTQbEm2ZU7"
      },
      "source": [
        "\n",
        "\n",
        "Если представить находящуюся выше матрицу 5х5 как картинку: матрицу интенсивности пикселей, где 0 это черный, а 3 это белый, а 1 и 2 темно-серый и светло-серый, то получим некоторую картинку, к которой применяем нашу свертку - квадрат 3х3. На данной картинке это квадрат со значениями 0,1,2,2,2,0,0,1,2. Применяем свертку, то есть перемножаем ячейки свертки и картинки. Например, для первой ячейки выходной матрицы:\n",
        "\n",
        "\n",
        "$3*0+3*1+2*2+0*2+0*2+1*0+3*0+1*1+2*2=12$\n",
        "\n",
        "В целом, мы подаем на вход картинку, а получаем на выходе рассчитанные по ней коэффициенты."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vw2K1BACsVGb"
      },
      "source": [
        "# Многоканальность"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ELbnCvKxsf02"
      },
      "source": [
        "Если раньше мы работали с черно-белыми изображениями, то в этот раз изображения цветные. Поэтому вместо одного канала мы теперь имеем три - по числу цветов RGB модели. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OHQIBdXDtZgj"
      },
      "source": [
        "![channelsUrl](https://neurohive.io/wp-content/uploads/2018/07/rgb-svertochnaja-neiroset.gif \"Сhannels\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o7Tq2ULLtxWf"
      },
      "source": [
        "Свертка проходит по каждому из каналов, а затем суммирует их."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oOSTXr6Btljn"
      },
      "source": [
        "![channelsSumUrl](https://neurohive.io/wp-content/uploads/2018/07/glubokaja-svertochnaja-neironnaja-set.gif \"Сhannels_Sum\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yXzk_MMkt0ll"
      },
      "source": [
        "Таким образом,  нейронная сеть будет принимать на вход изображения размером nxn и 3 канала. Например, (150,150,3), как в нашей сети."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ws06a1MgsGEi"
      },
      "source": [
        "# Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TiqsKS2hsLoy"
      },
      "source": [
        "Еще один специальный слой, явяющийся подвыборочным. Он используется с целью уменьшения размерности предыдущего слоя. Если на предыдущей операции свертки уже были выявлены некоторые признаки, то для дальнейшей обработки настолько подробное изображение уже не нужно, и оно уплотняется до менее подробного. К тому же фильтрация уже ненужных деталей помогает не переобучаться.\n",
        "\n",
        "Чаще всего используется уменьшение изображения в два раза путем использования матрицы 2х2 через операцию взятия максимума."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Ozs7uuJwY15"
      },
      "source": [
        "# Теперь поговорим о предобученных сетях"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yHHpP_7NwgTV"
      },
      "source": [
        "Обучение нейронной сети занимает не только много времени, но и требует большой размеченной выборки. Конечно, можно создавать свои сети с нуля и подбирать сеть для каждого конкретного случая. А можно упростить себе жизнь и взять для нашей задачи уже готовую нейронную сеть, обученную в течение долгого времени и показавшую хорошие результаты на своей задаче. Такая техника называется Transfer Learning или Перенос обучения.\n",
        "\n",
        "То есть, Transfer Learning - это процесс дообучения на новых данных какой-либо нейросети, уже обученной до этого на других данных, обычно на каком-нибудь хорошем, большом (миллионы картинок) датасете.\n",
        "\n",
        "Например, у нас есть сеть, хорошо распознающая самолет на картинке или танк. А мы хотим применить ее для распознавания кошек и собак. Так как на первых слоях нейронной сети происходит общая оценка изображения и мы не успеваем дойти до спецефичных признаков, мы можем использовать такую сеть для распознавания котов и собак.\n",
        "\n",
        "Есть три основных пути:\n",
        "* Взять предобученную на других данных нейронную сеть и просто предсказать наши картинки:\n",
        "\n",
        " +Не надо тратить время на обучение\n",
        "\n",
        " -Точность будет низкая для нашей задачи, если она сильно отличается\n",
        "\n",
        "* Взять предобученную на других данных нейронную сеть, добавить к ней новые слои и обучить только их\n",
        "\n",
        " +Сокращается время на обучение, происходит подгон под нашу задачу\n",
        "\n",
        " -Точность будет выше, однако добавление новых слоев может перегрузить сеть\n",
        "\n",
        "* Взять предобученную на других данных нейронную сеть, добавить новые слои. Но вместе с тем обучить не только новые слои, но и часть предобученной сети. Этот метод носит название Fine Tuning или Тонкая настройка.\n",
        "\n",
        " +Обучается не вся сеть, а только часть, отвечающая за специфичные признаки изображения\n",
        "\n",
        " -Точность должна возрасти, однако вероятно переобучение\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KKHzuWHG0evx"
      },
      "source": [
        "В зависимости от количества и природы Ваших данных есть выбор из нескольких стратегий Transfer Learning, а именно:\n",
        "\n",
        "* *У Вас **мало данных** ($\\le$ 10k), и они **похожи** на данные, на которых была обучена сеть до этого*  \n",
        "\n",
        "Можно использовать просто готовую модель. Но если точность вышла низкая, можно использовать второй путь. Если применить Fine-Tuning (3 способ), то сеть может переобучиться, поскольку данных мало.\n",
        "* *У Вас **мало данных** ($\\le$ 10k), и они **не похожи** на данные, на которых была обучена сеть до этого*  \n",
        "\n",
        "Самый плохой вариант. Хорошим выходом будет второй вариант, но возможно придется выкинуть часть последних слоев преобученной сети и тогда уже добавить свой.\n",
        "* *У Вас **много данных** ($\\ge$ 10k), и они **похожи** на данные, на которых была обучена сеть до этого*  \n",
        "\n",
        "Fine Tuning здесь подходит больше всего.\n",
        "* *У Вас **много данных** ($\\ge$ 10k), и они **не похожи** на данные, на которых была обучена сеть до этого*\n",
        "\n",
        "Обычно здесь оставляют архитектуру сети и используют запомненные веса как начальные. А потом заново обучают всю сеть."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XKVOY5WT29xU"
      },
      "source": [
        "Нашей стратегией в этой работе будет первый вариант."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sSO4NFDLZhDF"
      },
      "source": [
        "# Предобученная сеть VGG-16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FiBRxnlMxgT8"
      },
      "source": [
        "VGG-16 — модель сверточной нейронной сети, предложенная K. Simonyan и A. Zisserman из Оксфордского университета в статье “Very Deep Convolutional Networks for Large-Scale Image Recognition”. Модель достигает точности 92.7% — топ-5, при тестировании ImageNet в задаче распознавания объектов на изображении. Этот датасет состоит из более чем 14 миллионов изображений, принадлежащих к 1000 классам."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VGivCyLzaslA"
      },
      "source": [
        "Архитектуру данной сети вы можете увидеть на картинке.\n",
        "\n",
        "На момент создания VGG люди уже заметили, что чем больше слоев в нейросети, тем выше ее точность. Заменяя большие фильтры на несколько фильтров 3$\\times$3 исследователи получили глубокую нейросеть с меньшим количеством параметров. Архитектура VGG-16 (версии VGG с 16 слоями) представлена на картинке ниже:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jXXirCVqaslE"
      },
      "source": [
        "<img src=\"https://cdn-images-1.medium.com/max/1040/1*0Tk4JclhGOCR_uLe6RKvUQ.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hyiBl5hsaslJ"
      },
      "source": [
        "Когда говорят VGG, то чаще всего имеют ввиду VGG-16 или VGG-19. Более глубоких версий VGG нет, так как после 19 слоев точность начинает падать."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BRWqz65kGz1H"
      },
      "source": [
        "#Основные шаги по выполнению лабораторной работы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8BNBKwW8d7Ik"
      },
      "source": [
        "##Подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "36v49-4elSNS"
      },
      "source": [
        "Для начала работы подготовим данные"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vBHKF8dWeCbB"
      },
      "source": [
        "Скачайте файл train.zip с набором изображений кошек и собак с сайта соревнования Kaggle [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/data) и распакуйте его. Создайте папку cat_dogs (нажиамем правой кнопкой где-нибудь в поле, где находится sample_data, нажимаем new folder) и сделайте upload для 500 снимков кошек (cat0.jpg-cat499.jpg) и 500 собак (dog0.jpg-dog499.jpg). \n",
        "\n",
        "Чем на большем объеме данных будет обучаться ваша сеть, тем лучше, но это так же сильно увеличит время обучения сети. В реальных задачах это нормально, если  обучение нейронной сети на большом объеме данных занимает более 12 часов.  При обучении на всех изображениях точность продемонстрированных ниже сетей будет достигать 97%.\n",
        "\n",
        "В рамках данной работы мы возьмем только 500 изображений, для экономии учебного времени."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xu4nR89RlT75"
      },
      "source": [
        "Распределим эти фотографии по папкам: train, test и val. \n",
        "\n",
        "Каждая папка будет содержать две подпапки: cats и dogs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7WlMsw3Zd_I-",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v5A2gTOfeO7Z",
        "colab": {}
      },
      "source": [
        "# Каталог с набором данных\n",
        "data_dir = './train_data/train_500'\n",
        "# Каталог с данными для обучения\n",
        "train_dir = 'train'\n",
        "# Каталог с данными для проверки\n",
        "val_dir = 'val'\n",
        "# Каталог с данными для тестирования\n",
        "test_dir = 'test'\n",
        "# Часть набора данных для тестирования\n",
        "test_data_portion = 0.15\n",
        "# Часть набора данных для проверки\n",
        "val_data_portion = 0.15\n",
        "# Количество элементов данных в одном классе\n",
        "nb_images = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GCdpOq3Qlu6a"
      },
      "source": [
        "Функция создания каталога с двумя подкаталогами по названию классов: cats и dogs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6aO_T8vYky5U",
        "colab": {}
      },
      "source": [
        "def create_directory(dir_name):\n",
        "    if os.path.exists(dir_name):\n",
        "        shutil.rmtree(dir_name)\n",
        "    os.makedirs(dir_name)\n",
        "    os.makedirs(os.path.join(dir_name, \"cats\"))\n",
        "    os.makedirs(os.path.join(dir_name, \"dogs\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VmcuPGK8lymp"
      },
      "source": [
        "Создание структуры каталогов для обучающего, проверочного и тестового набора данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dr3fie4uk3Au",
        "colab": {}
      },
      "source": [
        "create_directory(train_dir)\n",
        "create_directory(val_dir)\n",
        "create_directory(test_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0xUwnLmCl0uA"
      },
      "source": [
        "\n",
        "Функция копирования изображений в заданный каталог. Изображения котов и собак копируются в отдельные подкаталоги"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "paGtIfMCk-Dk",
        "colab": {}
      },
      "source": [
        "def copy_images(start_index, end_index, source_dir, dest_dir):\n",
        "    for i in range(start_index, end_index):\n",
        "        shutil.copy2(os.path.join(source_dir, \"cat.\" + str(i) + \".jpg\"), \n",
        "                    os.path.join(dest_dir, \"cats\"))\n",
        "        shutil.copy2(os.path.join(source_dir, \"dog.\" + str(i) + \".jpg\"), \n",
        "                   os.path.join(dest_dir, \"dogs\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fSgB_lVGl297"
      },
      "source": [
        "\n",
        "Расчет индексов наборов данных для обучения, проверки и тестирования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "clDnZ7i3lAAY",
        "outputId": "022a71ec-a11c-4886-c895-936688713486",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "start_val_data_idx = int(nb_images * (1 - val_data_portion - test_data_portion))\n",
        "start_test_data_idx = int(nb_images * (1 - test_data_portion))\n",
        "print(start_val_data_idx)\n",
        "print(start_test_data_idx)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "350\n",
            "425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G5A2Ks-AmHDr"
      },
      "source": [
        "Копирование изображений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-I1T0i57lCUf",
        "colab": {}
      },
      "source": [
        "copy_images(0, start_val_data_idx, data_dir, train_dir)\n",
        "copy_images(start_val_data_idx, start_test_data_idx, data_dir, val_dir)\n",
        "copy_images(start_test_data_idx, nb_images, data_dir, test_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dDZMkIv4mDBB"
      },
      "source": [
        "## Создание нейронной сети на базе предварительно обученной нейронной сети VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fijrMm_43PNg"
      },
      "source": [
        "Сеть VGG16 ранее обучалась на похожих изображениях. Поэтому мы попробуем два способа:\n",
        "* добавим свои слои к сети VGG16, но саму сеть обучать не будем\n",
        "* разморозим только последний слой сети VGG16 и обучим с новыми слоями"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AVuVnIXmmYO_"
      },
      "source": [
        "### Импортируем необходимые библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "of2jctaTlFst",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.models import Sequential, Model\n",
        "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.python.keras.applications import VGG16\n",
        "from tensorflow.python.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hCRdvqBEmnL5"
      },
      "source": [
        "Определим оставшиеся константы:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dRVEMD9mmqt8",
        "colab": {}
      },
      "source": [
        "# Размеры изображения\n",
        "img_width, img_height = 150, 150\n",
        "# Размерность тензора на основе изображения для входных данных в нейронную сеть\n",
        "input_shape = (img_width, img_height, 3)\n",
        "# Размер мини-выборки\n",
        "# old value batch_size = 64\n",
        "batch_size = 100\n",
        "# Количество изображений для обучения\n",
        "nb_train_samples = 700\n",
        "# Количество изображений для проверки\n",
        "nb_validation_samples = 150\n",
        "# Количество изображений для тестирования\n",
        "nb_test_samples = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V1A1H5k3pmQk"
      },
      "source": [
        "Следующей строчкой мы загрузим предварительно обученную сеть VGG16. Сразу установим входную размерность, а именно 150 пикселей ширины на 150 пикселей выосоты на 3 канала цвета."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ULsV6Ua9paeh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "fe48dbb6-c53a-4c76-852e-6063afb4b4cb"
      },
      "source": [
        "vgg16_net = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "syeEUTWdpv3V"
      },
      "source": [
        "\"Замораживаем\" веса предварительно обученной нейронной сети VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7OyKAKsvp1CA",
        "colab": {}
      },
      "source": [
        "vgg16_net.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-4BfTGV7p4hT"
      },
      "source": [
        "Посмотрим на структуру загруженной сети."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O-kFTd-Vp2ZH",
        "outputId": "e47b0c08-1ecf-4368-b5ea-116b805ad5e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        }
      },
      "source": [
        "vgg16_net.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IQeY63qWp-Lq"
      },
      "source": [
        "Теперь давайте добавим к имеющейся сети несколько новых слоев. Возьмем выходные данные VGG16 нейронной сети и подадим их на вход нашего нового слоя Flatten, который преобразует эти данные в одномерный вектор. \n",
        "\n",
        "Dense - это уже знакомый нам полносвязный слой. \n",
        "\n",
        "Дальше идет слой Dropout, который \"исключает\" заданный процент нейронов. “Исключение” нейрона означает, что при любых входных данных или параметрах он возвращает 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RYK_n8BSp3-h",
        "colab": {}
      },
      "source": [
        "x = vgg16_net.output\n",
        "x = Flatten(name=\"flatten\")(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = Model(inputs=vgg16_net.input, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bLEW79IvrTMB"
      },
      "source": [
        "Посмотрим на структуру получившейся составной сети. Мы можем увидеть новые слои в конце."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rm5oylmHrSt0",
        "outputId": "35a24482-f277-4768-8264-cdc4d7abc20e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 16,812,353\n",
            "Trainable params: 2,097,665\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pam3-x0ErZ2n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3ee52778-2323-4a10-e3f6-6ccf2572211f"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8zy3cvLfsC3c"
      },
      "source": [
        "### Создаем генератор изображений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PT8hvopFpUBG"
      },
      "source": [
        "Еще один способ подать данные в сеть - это с помощью генератора изображений. Процесс предподготовки данных (например,оптимальное разбитие на выборки, нормализация или изменения размера изображения) имеет большое значение для нейронных сетей. Некоторые из этих процессов можно прописывать отдельно, а можно применить генератор изображений. \n",
        "\n",
        "В данном случае мы сделаем несколько вещей при помощи генератора:\n",
        "* Нормализуем данные\n",
        "* Изменим размерность картинок на подходящий в нейронную сеть\n",
        "* Пропишем размер мини-выборки\n",
        "\n",
        "Мы уже сталкивались с данными, в которых представителей одного класса больше, чем других. В таком случае часто применяется искуственная генерация изображений. Например, путем поворота или отражения картинки, увеличения или уменьшения, размытия четкоси. Все это позволяет делать генератор изображений, однако в данной работы мы не будем останавливаться на этом. Используем генератор для описанных выше целей.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VJ-vB0oNsT7R"
      },
      "source": [
        "Итак, генератор изображений создается на основе класса ImageDataGenerator. Генератор делит значения всех пикселов изображения на 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CZci8neOrojf",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n3QkgZRysX8n"
      },
      "source": [
        "\n",
        "Генератор данных для обучения, проверки и тестирования на основе изображений из каталога"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0B3_JBn3sIBx",
        "outputId": "17611e86-766f-4b18-a191-9791918d3728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 700 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3RJ-H3c7sJVu",
        "outputId": "de483549-9087-41bd-cf00-9e84f91e7def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 150 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gVRDyRIqsLTh",
        "outputId": "f2ab6976-6dc0-409c-f19f-36074a98c765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 150 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XbSvJo2LsgDh"
      },
      "source": [
        "### Обучаем модель с использованием генераторов\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lAIVYY9esNE3",
        "outputId": "694fc271-5366-48c4-8dd8-7ef2f1d3650a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=2,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "# old epochs = 10"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "6/7 [========================>.....] - ETA: 21s - loss: 0.8205 - acc: 0.4567Epoch 1/2\n",
            "7/7 [==============================] - 176s 25s/step - loss: 0.8109 - acc: 0.4686 - val_loss: 0.6904 - val_acc: 0.5700\n",
            "Epoch 2/2\n",
            "6/7 [========================>.....] - ETA: 21s - loss: 0.7553 - acc: 0.5200Epoch 1/2\n",
            "7/7 [==============================] - 173s 25s/step - loss: 0.7560 - acc: 0.5200 - val_loss: 0.6628 - val_acc: 0.5900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f33117ebf60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "doc9og1dtSRp"
      },
      "source": [
        "### Оценим качество сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UXvmyb4Csjwa",
        "outputId": "6e62cfb7-1bde-4b6c-dc60-2f384599dfe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
        "# Аккуратность на тестовых данных: 80.47% b=64 e=10\n",
        "# Аккуратность на тестовых данных: 71.88% b=128 e=5\n",
        "# Аккуратность на тестовых данных: 69.00% b=128 e=2"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Аккуратность на тестовых данных: 61.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P4ddL6UctpPX"
      },
      "source": [
        "### Применение метода Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6fDPVYrztwFd"
      },
      "source": [
        "\"Размораживаем\" последний сверточный блок сети VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Iwp6Z_nZtzP5",
        "colab": {}
      },
      "source": [
        "vgg16_net.trainable = True\n",
        "trainable = False\n",
        "for layer in vgg16_net.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        trainable = True\n",
        "    layer.trainable = trainable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9ix4pEQ2t8KE"
      },
      "source": [
        "Посмотрим на количество обучаемых параметров, оно должно было измениться."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N3Za9hQ9xAyn",
        "outputId": "3302cb0d-eb1e-4a73-87c9-aea476e2da1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "Total params: 9,732,929\n",
            "Trainable params: 2,097,665\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t7NpYe7euD2T",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oKg3y9gc34YX"
      },
      "source": [
        "Возьмем небольшое количество эпох, чтобы избежать переобучения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "79yXfK-3uHeg",
        "outputId": "2be22d1a-a680-41c0-f9fa-e2b63866c606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=2,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "6/7 [========================>.....] - ETA: 26s - loss: 0.6911 - acc: 0.5883Epoch 1/2\n",
            "7/7 [==============================] - 207s 30s/step - loss: 0.6959 - acc: 0.5800 - val_loss: 0.5920 - val_acc: 0.7000\n",
            "Epoch 2/2\n",
            "6/7 [========================>.....] - ETA: 25s - loss: 0.5969 - acc: 0.6600Epoch 1/2\n",
            "7/7 [==============================] - 204s 29s/step - loss: 0.5905 - acc: 0.6671 - val_loss: 0.5270 - val_acc: 0.7700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3311fe7668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XRbXQ4F0uKf1",
        "outputId": "e385fdb8-1d3b-44ca-f71f-fae00ec636c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "# Аккуратность на тестовых данных: 82.81% b=64 e=10\n",
        "# Аккуратность на тестовых данных: 81.25% b=128 e=5\n",
        "# Аккуратность на тестовых данных: 81.00% b=128 e=2"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Аккуратность на тестовых данных: 81.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8fRk2VpJzgYJ"
      },
      "source": [
        "# Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7cRk_Fw1zj2q"
      },
      "source": [
        "1.  Запустите код, приведенный для примера, выше (обучите сети, проанализируйте результаты)\n",
        "2. Создайте собвтенную нейронную сеть на базе предобученной сети VGG16 (можно взять другую предобученную сеть по желанию, например, AlexNet, Interception и  т.д). \n",
        "\n",
        "То есть в примере выше нужно поменять добавляемые слои после Flattern на ваш вариант. Например, вы можете использовать:\n",
        "* Один дополнительный полносвязный слой Dense после Dropout\n",
        "* Dropout с разным процентом исключения нейронов\n",
        "* Также вы можете поменять количество эпох или размер мини-выборки\n",
        "\n",
        "3. Сравните полученные результаты и сделайте выводы.\n",
        "\n",
        "! не забудьте заново загрузить VGG16 или снова заморозить все слои в уже загруженной модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ0xItcgz9EM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile(\"./train_500.zip\", 'r') as zip_ref:\n",
        "#     zip_ref.extractall(\"./train_data/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIJXDan00VYy",
        "colab_type": "text"
      },
      "source": [
        "# Обучение с аугментацией данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzC5qhQq0aJu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7b3dd605-6dd4-4a12-e2ad-170fa1533820"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "\n",
        "# Аугментация 1\n",
        "datagen_train = ImageDataGenerator(rescale=1. / 255, \n",
        "  rotation_range=30,\n",
        "\tzoom_range=0.15,\n",
        "\thorizontal_flip=True)\n",
        "\n",
        "datagen_test_val = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = datagen_train.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "val_generator = datagen_test_val.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "test_generator = datagen_test_val.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 700 images belonging to 2 classes.\n",
            "Found 150 images belonging to 2 classes.\n",
            "Found 150 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8E6ySK437Wr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "ca1e81fb-4e94-4487-d6cb-2161f1619ff7"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=2,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "# Аккуратность на тестовых данных без аугментации: 81.00% b=128 e=2\n",
        "# Аккуратность на тестовых данных с аугментацией: 89.00%"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "6/7 [========================>.....] - ETA: 26s - loss: 0.5700 - acc: 0.6917Epoch 1/2\n",
            "7/7 [==============================] - 212s 30s/step - loss: 0.5737 - acc: 0.6900 - val_loss: 0.4739 - val_acc: 0.7900\n",
            "Epoch 2/2\n",
            "6/7 [========================>.....] - ETA: 25s - loss: 0.5174 - acc: 0.7500Epoch 1/2\n",
            "7/7 [==============================] - 206s 29s/step - loss: 0.5187 - acc: 0.7500 - val_loss: 0.4117 - val_acc: 0.8100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3311e17b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOsJmHyh6FDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28281955-7fd6-40ba-8fc2-e61af45cde8c"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Аккуратность на тестовых данных: 89.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DuJ6JIP5mkQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "95febfa9-0aa6-4961-e4ac-58cc4ec9259d"
      },
      "source": [
        "# Аугментация 2\n",
        "datagen_train = datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "datagen_test_val = ImageDataGenerator(rotation_range=20)\n",
        "\n",
        "train_generator = datagen_train.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "val_generator = datagen_test_val.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "test_generator = datagen_test_val.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 700 images belonging to 2 classes.\n",
            "Found 150 images belonging to 2 classes.\n",
            "Found 150 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzEeUVLX6qlT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "a47b01cd-7df4-4f68-d239-9b35b02a7d77"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=2,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "# Аккуратность на тестовых данных без аугментации  : 81.00% b=128 e=2\n",
        "# Аккуратность на тестовых данных с аугментацией 1 : 89.00%\n",
        "# Аккуратность на тестовых данных c аугментацией 2 : 90.00%"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "6/7 [========================>.....] - ETA: 26s - loss: 5.2486 - acc: 0.7550Epoch 1/2\n",
            "7/7 [==============================] - 214s 31s/step - loss: 5.0580 - acc: 0.7557 - val_loss: 1.6945 - val_acc: 0.8800\n",
            "Epoch 2/2\n",
            "6/7 [========================>.....] - ETA: 25s - loss: 4.5311 - acc: 0.7750Epoch 1/2\n",
            "7/7 [==============================] - 207s 30s/step - loss: 4.2019 - acc: 0.7814 - val_loss: 1.6219 - val_acc: 0.8700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3311992240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmwxVBqZ6nN-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f209068-af60-48fc-9d52-b9e9b14dfab3"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Аккуратность на тестовых данных: 90.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJTQ6koK6-EH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6e714d95-8f2d-44c1-c2f5-f81c7565eba4"
      },
      "source": [
        "# Аугментация 3\n",
        "datagen_train = ImageDataGenerator(rescale=1. / 255, \n",
        "  rotation_range=60,\n",
        "\tzoom_range=0.20,\n",
        "\thorizontal_flip=True)\n",
        "\n",
        "datagen_test_val = ImageDataGenerator(rescale=1. / 255, rotation_range=60)\n",
        "\n",
        "train_generator = datagen_train.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "val_generator = datagen_test_val.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "test_generator = datagen_test_val.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 700 images belonging to 2 classes.\n",
            "Found 150 images belonging to 2 classes.\n",
            "Found 150 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnwyYlij7LQc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "23605b3b-4a84-46d0-a3ef-dc00a962abc9"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=1e-5), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=2,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "# Аккуратность на тестовых данных без аугментации  : 81.00% b=128 e=2\n",
        "# Аккуратность на тестовых данных с аугментацией 1 : 89.00%\n",
        "# Аккуратность на тестовых данных c аугментацией 2 : 90.00%\n",
        "# Аккуратность на тестовых данных c аугментацией 3 : 86.00%"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "6/7 [========================>.....] - ETA: 27s - loss: 0.5847 - acc: 0.6800Epoch 1/2\n",
            "7/7 [==============================] - 217s 31s/step - loss: 0.5756 - acc: 0.6914 - val_loss: 0.4884 - val_acc: 0.7400\n",
            "Epoch 2/2\n",
            "6/7 [========================>.....] - ETA: 25s - loss: 0.5304 - acc: 0.7317Epoch 1/2\n",
            "7/7 [==============================] - 207s 30s/step - loss: 0.5300 - acc: 0.7271 - val_loss: 0.4555 - val_acc: 0.8200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f330bfd8828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTI2Ngrg7U6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "676ae1fe-a496-4c4d-af97-5eacf9903a16"
      },
      "source": [
        "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
        "print(\"Аккуратность на тестовых данных: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Аккуратность на тестовых данных: 86.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCyJEUPh-duZ",
        "colab_type": "text"
      },
      "source": [
        "## Итог\n",
        "Таким обзом, мы получаем такие результаты\n",
        "* Аккуратность на тестовых данных без аугментации  : 82.81% b=64 e=10\n",
        "* Аккуратность на тестовых данных без аугментации  : 81.25% b=128 e=5\n",
        "* Аккуратность на тестовых данных без аугментации  : 81.00% b=128 e=2\n",
        "* Аккуратность на тестовых данных с аугментацией 1 : 89.00% b=128 e=2\n",
        "* Аккуратность на тестовых данных c аугментацией 2 : 90.00% b=128 e=2\n",
        "* Аккуратность на тестовых данных c аугментацией 3 : 86.00% b=128 e=2\n",
        "\n",
        "<br><br>\n",
        "Как из этого видно - выбор правильных параметров при обучении является основным показателем точности и достоверности нашей нейронной сети. Также, чтобы улучшить работу нашей сети мы можем добавить аугментацию данных, что в нашем случае, экстремально дал результат точности до 90%\n",
        "\n",
        "![](https://i.pinimg.com/564x/9d/09/6c/9d096c3a6a51413edee5385ca50dd0a2.jpg)"
      ]
    }
  ]
}