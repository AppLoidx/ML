{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab4_Clustering_ready.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtyGsN41cJfW",
        "colab_type": "text"
      },
      "source": [
        "# Введение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUax1Iu4-uMR",
        "colab_type": "text"
      },
      "source": [
        "В двух предыдущих лабораторных работах мы рассматривали классические методы машинного обучения, которые относились к категории \"Обучение с учителем\". То есть, у нас был вектор X с признаками (атрибутами) и вектор Y c правильными ответами. При обучении без учителя у нас есть только объекты $X=\\{x_1, x_2, ..., x_m\\} \\in \\mathbb{R^n}$ и нет ответов к ним, то есть мы имеем неразмеченную выборку. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvhsHcjBBodz",
        "colab_type": "text"
      },
      "source": [
        "Обучение без учителя можно поделить на три основных типа задач:\n",
        "* кластеризация\n",
        "* уменьшение размерности (обощение)\n",
        "* поиск правил (ассоциация)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLNe3MPJj1s4",
        "colab_type": "text"
      },
      "source": [
        "Самой известной и популярной, пожалуй, является **кластеризация**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdAunv-s-u3f",
        "colab_type": "text"
      },
      "source": [
        "Примеры применения кластеризации:\n",
        "* Сегментация рынка (типов покупателей, лояльности)\n",
        "* Объединение близких точек на карте\n",
        "* Сжатие изображений\n",
        "* Анализ и разметки новых данных\n",
        "* Детекторы аномального поведения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnA_utIej95A",
        "colab_type": "text"
      },
      "source": [
        "Постановка задачи: \n",
        "* Дано: объекты $X=\\{x_1, x_2, ..., x_m\\} \\in \\mathbb{R^n}$\n",
        "* Требуется разбить это множество объектов на группы таким образом, чтобы элементы внутри одной группы были похожи друг на друга, а элементы из разных групп отличались. Такие группы похожих объектов мы будем называть **кластеры**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqQj2wqyqxna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image \n",
        "from IPython.core.display import HTML \n",
        "Image(url= \"http://neerc.ifmo.ru/wiki/images/7/74/Clusters.png\", width=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40fXISlhpjmz",
        "colab_type": "text"
      },
      "source": [
        "Следует отличать методы кластеризации от методов классификации. Методы классификации — это методы обучения с учителем. Это значит, что для каждого объекта нам известна его истинная метка принадлежности к классу. Затем, имея истинные метки, предсказания алгоритма и некоторую функцию потерь, алгоритмы классификации как-то подстраиваются так, чтобы допускать меньше ошибок на данных. Алгоритмы же кластеризации никак не используют информацию об истинных метках объектов и оперируют лишь похожестью объекта. Ну а что такое похожесть, в каждом алгоритме кластеризации определяется по-своему. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnYVlWEbp4x_",
        "colab_type": "text"
      },
      "source": [
        "Основная цель кластеризации заключается в том, чтобы выявить структуру в данных. С помощью методов кластеризации мы можем автоматически найти группу похожих объектов, возможно, выделить аномалии, какие-то изолированные объекты, которые требуют дополнительного изучения или выбрасывания из данных, и кластеризация позволяет провести более детальный анализ самих кластеров. Иногда бывает полезно построить отдельные модели на каждом кластере вместо того, чтобы строить одну модель на всех данных и получить какой-то мусор. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPMJvrJpqAtA",
        "colab_type": "text"
      },
      "source": [
        "Существует очень много методов кластеризации. \n",
        "*    методы кластеризации на основе прототипов\n",
        "*    иерархические методы кластеризации\n",
        "*    плотностные методы кластеризации\n",
        "*    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRmFdzcnt_gR",
        "colab_type": "text"
      },
      "source": [
        "*Методы разбиения на основе прототипов* заключаются в том, что кластеры характеризуются некоторым базовым элементом или прототипом.  Например, в методе k-средних кластер характеризуется центроидом — центром масс объектов, из которых он состоит. Обычно в результате применения алгоритмов из этой группы мы получаем строгое разбиение всех наших объектов на кластеры, то есть одному объекту соответствует одна метка кластера. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvfdVQcAqC0Z",
        "colab_type": "text"
      },
      "source": [
        "*Иерархические алгоритмы* позволяют получить целую структуру вложенных друг в друга кластеров. Иногда это бывает полезно для того, чтобы понять вообще структуру наших данных от начала до конца. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN8aPzdqujpy",
        "colab_type": "text"
      },
      "source": [
        "*Плотностные методы кластеризации* действуют совершенно иначе. В них кластер определяется, как область с большой плотностью точек, с большой плотностью объектов. Такая формулировка кластера позволяет выявлять произвольные формы кластеров и выделять объекты-выбросы, то есть элементы, вокруг которых нет других точек. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxI1A1xTxJV3",
        "colab_type": "text"
      },
      "source": [
        "В рамках данной лабораторной работы мы рассмотрим метод k-means (к-средних), относящийся к методам кластеризации на основе прототипов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hUxrGPPx5uf",
        "colab_type": "text"
      },
      "source": [
        "##Метод К-средних"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkZWOik5yMOG",
        "colab_type": "text"
      },
      "source": [
        "Итак, у нас есть некоторой множество объектов $X=\\{x_1, x_2, ..., x_m\\} \\in \\mathbb{R^n}$. Мы хотим разделить это множество на $K$ кластеров, каждый из которых характеризуется центроидом:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGCSaLQeypHn",
        "colab_type": "text"
      },
      "source": [
        "Кластер $C_k\\leftrightarrow$ центроид $\\mu_k$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVa1Z0P9ypN3",
        "colab_type": "text"
      },
      "source": [
        " Объект относится к соответствующему кластеру, если его центроид находится ближе других центроидов к этому объекту:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Clv4vFtGypTO",
        "colab_type": "text"
      },
      "source": [
        "объект $x_i\\in C_k \\Leftrightarrow \\mu_k = arg\\ \\underset{\\mu_j}{min}||x_i - \\mu_i||^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8GL9nZ70rNg",
        "colab_type": "text"
      },
      "source": [
        "Будем кластеризовывать объекты таким образом, чтобы минимизировать сумму квадратов расстояния между объектом и ближайшим к нему центроидом по всем кластерам:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRnf9P951c-m",
        "colab_type": "text"
      },
      "source": [
        "$L(C)=\\sum\\limits_{j=1}^k\\sum\\limits_{x_i \\in C_j}{||x_i-\\mu_j||^2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JNYEgZq3DUZ",
        "colab_type": "text"
      },
      "source": [
        "Если взять производную по $\\mu$, то становится понятно, что лучше всего выражать центроид именно как центр масс объектов, которые относятся к соответствующему кластеру."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIoh93aS3DbY",
        "colab_type": "text"
      },
      "source": [
        "$\\mu_k=\\frac{\\sum\\limits_{x_i \\in C_k}x_i}{|C_k|}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92z1q-CG3DkJ",
        "colab_type": "text"
      },
      "source": [
        "Теперь у нас есть формулировка критерия и мы знаем, как считать центроид.  Но для того, чтобы найти глобальный минимум этого функционала нужно перебирать все возможные разбиения объектов на к-кластеров, что, конечно же, не так интересно. Спасает нас алгоритм к-средних, который позволяет найти локальный минимум этого критерия. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkvOqoRQ4h4h",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Алгоритм k-средних"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE9lygQb4p5R",
        "colab_type": "text"
      },
      "source": [
        "Вход: Объекты $X$, $k$ - количество кластеров\n",
        "1.    **Инициализация центроидов** $\\mu_1, \\mu_2, ..., \\mu_k$\n",
        "2.    **Обновление кластеров:** объекты приписываются к ближайшему центроиду\n",
        "3.    **Обновление центроидов:** пересчет положения центроидов как центр масс объектов, которые лежат в соответствующем кластере "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqEu10D64p-5",
        "colab_type": "text"
      },
      "source": [
        "Шаги 2 и 3 продолжаются до тех пор пока не выполнятся некоторые правила остановок, например, будет достигнуто какое-то максимальное количество итераций или пока кластеры не перестанут меняться."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A0c_41j7UbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(url= \"https://stanford.edu/~cpiech/cs221/img/kmeansViz.png\", width=600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47AKgQLj4qDH",
        "colab_type": "text"
      },
      "source": [
        "Пояснения к рисунку: алгоритм K-средних. Примеры обучения показаны точками, а центроиды  показаны крестиками. \n",
        "*    (а) Исходный набор данных. \n",
        "*    (b) Случайные начальные центроидов. \n",
        "*    (c) Приписываем объекты к ближайшему центроиду (на картинке окрашиваем их в соответствующий цвет) \n",
        "*    (d) Пересчитываем положение цетроида как центра масс для всех объектов, приписанных к данному центроиду, и перемещаем его в новое положение\n",
        "*    (e) Приписываем объекты к ближайшему центроиду (на картинке окрашиваем их в соответствующий цвет) \n",
        "*    (f) Пересчитываем положение цетроида как центра масс для всех объектов, приписанных к данному центроиду, и перемещаем его в новое положение\n",
        "\n",
        "Останавливаем выполнение алгоритма, так как положение центроидов не меняется. Кластеризация закончена"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb7Mmdf34qH4",
        "colab_type": "text"
      },
      "source": [
        "Результирующее разбиение на кластеры, которое получается после алгоритма к-средних, в основном, зависит от следующих факторов. \n",
        "*    начальная инициализация центроидов. Оказывается, что на одним и тех же данных при одних и тех же k, но при разной инициализации мы можем получить совершенно разное разбиение на кластеры. \n",
        "*    определение количества кластеров данных "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7rDTL2s-jLa",
        "colab_type": "text"
      },
      "source": [
        "####Варианты начальной инциализации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl_qPivA-PJP",
        "colab_type": "text"
      },
      "source": [
        "Базовые варианты начальной инициализации центроидов:\n",
        "1.    выбрать k-случайных объектов в наших данных в качестве центроидов и уже с этих центроидов начинать следующие шаги алгоритма. \n",
        "2.    использовать k-кластеров полученных после применения иерархической кластеризации с методом Уорда. \n",
        "3.    метод К-Means++: Первый центроид мы будем выбирать случайным образом среди всех точек в данных, которые у нас есть. Для каждой точки мы будем рассчитывать расстояние до ближайшего центроида, который ранее был уже нами инициализирован. В качестве следующего центроида мы будем выбирать также точки наших данных, но с вероятностью пропорционально как раз этому расстояние, которое мы посчитали на шаге предыдущем. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqFAOnsMCp99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.lib.display import YouTubeVideo\n",
        "YouTubeVideo('BIQDlmZDuf8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__2WvWvluw4p",
        "colab_type": "text"
      },
      "source": [
        "Данный ролик иллюстрирует начальную инициализацию центроидов по методу k-means++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW5TwwCNEhL8",
        "colab_type": "text"
      },
      "source": [
        "Пояснения к ролику:\n",
        "*    шаг 0: начальные данные\n",
        "*    шаг 1: среди всех точек случайным образом выбираем положение 1-го центроида  (крестик в левом верхнем углу). Пересчитываем квадрат расстояния для каждой точки от выбранного центроида. Размер точки теперь пропорционален квадрату расстояния. \n",
        "*    шаг 2: выбираем следующий центроид так, чтобы вероятность выбора точки была пропорциональна вычисленному для неё квадрату расстояния ([подробнее](https://ru.wikipedia.org/wiki/K-means%2B%2B) )\n",
        "\n",
        "шаг 1 и 2 повторяются пока не будут выбраны все центроиды"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6Ygz-fBEDF1",
        "colab_type": "text"
      },
      "source": [
        "####Определение количества кластеров данных "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClQoMFoJEDNH",
        "colab_type": "text"
      },
      "source": [
        "Есть несколько вариантов выбора количества кластеров $k$:\n",
        "*    использовать не стандартный метод k-mean, а модифицированный (X-means или intelligent k-means), который $k$ вычисляет автоматически\n",
        "*    использовать меры качеств кластеризации: для каждого k и разбиения мы будем считать меру качества кластеризации и в соответствии с этой мерой выберем лучшее разбиение и, соответственно, лучшее k.\n",
        "*    воспользоваться некоторыми эвристиками (например, методом Локтя)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvWjmRwQJKFk",
        "colab_type": "text"
      },
      "source": [
        "#####Метод локтя"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiKlpuPvEDVd",
        "colab_type": "text"
      },
      "source": [
        "Для каждого k будем считать значение критерия k-means: $$L^{(k)}(C)=\\sum\\limits_{j=1}^k\\sum\\limits_{x_i \\in C_j}{||x_i-\\mu_j||^2}$$\n",
        "Если расположить эти значения на графике, то мы получим примерно такую убывающая функцию. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sfBDi23IDnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(url= \"https://blog.bioturing.com/wp-content/uploads/2018/10/1_dChOocbcsLLT1fcxTxj2Ng.png\", width=500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3RRZDNOJ-k2",
        "colab_type": "text"
      },
      "source": [
        "Нам нужно найти такое k, начиная с которого значение критерия k-means будет убывать не слишком быстро. Этот эффект очень визуально похож на локоть и отсюда, собственно, название этого метода (Метод Локтя). Например, для данных на рисунке выше, таким k будет k равное 4. Важно понимать, что все эти эвристики и меры качества в кластеризации носят лишь рекомендательный характер."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NND1I316jnmL",
        "colab_type": "text"
      },
      "source": [
        "####Достоинства и недостатки алгоритма:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPgyc2MPjhs8",
        "colab_type": "text"
      },
      "source": [
        "Сильные стороны алгоритма:\n",
        "\n",
        "* Сравнительно высокая эффективность при простоте реализации\n",
        "* Высокое качество кластеризации\n",
        "* Возможность распараллеливания\n",
        "* Существование множества модификаций\n",
        "\n",
        "Недостатки алгоритма:\n",
        "\n",
        "* Количество кластеров является параметром алгоритма\n",
        "* Чувствительность к начальным условиям (Инициализация центров кластеров в значительной степени влияет на результат кластеризации)\n",
        "* Чувствительность к выбросам и шумам (Выбросы, далекие от центров настоящих кластеров, все равно учитываются при вычислении их центров)\n",
        "* Возможность сходимости к локальному оптимуму (Итеративный подход не дает гарантии сходимости к оптимальному решению)\n",
        "* Использование понятия \"среднего\" (Алгоритм неприменим к данным, для которых не определено понятие \"среднего\", например, категориальным данным)\n",
        "* слабая классификация сложных данных (ленточных кластеров, вложенных, пересекающихся и т.д.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c6k5BNtkm3r",
        "colab_type": "text"
      },
      "source": [
        "В качестве примера различных алгоритмов приведем результаты работы различных алгоритмов кластеризации для различных типов данных (k-means - самый первый столбик)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiQrmYAylg1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(url= \"http://neerc.ifmo.ru/wiki/images/thumb/2/28/Cluster_comparison.png/800px-Cluster_comparison.png\", width=800)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDPczr9jmI-y",
        "colab_type": "text"
      },
      "source": [
        "Если посмотреть на картинку, можно увидеть, что на данных примерах самая точная кластеризация у метода DBSCAN. Давайте рассмотрим этот метод"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJKPDhW6mhkP",
        "colab_type": "text"
      },
      "source": [
        "##Метод DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4TK23v3mocr",
        "colab_type": "text"
      },
      "source": [
        "DBSCAN (Density-based spatial clustering of applications with noise, плотностной алгоритм пространственной кластеризации с присутствием шума), как следует из названия, оперирует плотностью данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ66O07qmom0",
        "colab_type": "text"
      },
      "source": [
        "Суть метода (максимально упрощенно):\n",
        "предположим перед лекцией несколько групп студентов находятся в коридоре и ждут, когда освободится аудитория. Предположим, каждый студент - это отдельная точка. Кто-то стоит один, кто-то кучкуется группой, кто-то стоит вдоль стен. Как же выделить в такой толпе кластеры?\n",
        "Находим трёх любых близко стоящих человека и говорим им взяться за руки. Затем они начинают брать за руку тех, до кого могут дотянуться. Так по цепочке, пока никто больше не сможет взять кого-то за руку — это и будет первый кластер. Повторяем, пока не поделим всех. Те, кому вообще некого брать за руку — это выбросы, аномалии. Более подробно можно посмотреть [здесь](https://habr.com/ru/post/322034/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFIaa7C4movp",
        "colab_type": "text"
      },
      "source": [
        "Визуализация этого метода на примере не очень простых данных. Цветом выделены разные кластеры, выбросы (точки, не вошедшие ни в один кластер) остались неокрашенными."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBBCuNE7pgeR",
        "colab_type": "text"
      },
      "source": [
        "![dbscanUrl](https://cdn-images-1.medium.com/max/1600/1*tc8UF-h0nQqUfLC8-0uInQ.gif \"DBSCAN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay29YjDGreMM",
        "colab_type": "text"
      },
      "source": [
        "главные недостатки DBSCAN — неспособность соединять кластеры через проёмы, и, наоборот, способность связывать явно различные кластеры через плотно населённые перемычки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZb8n71x5-6Y",
        "colab_type": "text"
      },
      "source": [
        "Значительное влияние на работу алгоритма DBSCAN оказывают два его входных параметра: eps -радиус окрестности (это максимальное расстояние на котором две точки считаются соседями и могут быть отнесены к одному кластеру) и min_samples - минимальное количество точек, образующих кластер. Подбор этих параметров - важная часть настройки данного метода. Посмотрим это на примере небольшого набора \"синтетических\" данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOAjjat39rN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.datasets import make_blobs\n",
        "X, y = make_blobs(random_state=0, n_samples=30)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxAXonYjTYNe",
        "colab_type": "text"
      },
      "source": [
        "Визуализируем полученные данные (заодно посмотрим, как это делать с помощью библиотека matplotlib)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7XzmhxiTh2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams['figure.figsize']=(12,8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2iadKtmTpBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(X[:,0], X[:,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlntB6SJElTa",
        "colab_type": "text"
      },
      "source": [
        "Так выглядят наши данные. Давайте посмотрим на сколько кластеров поделит алгоритм DBSCAN такие данные в зависимости от параметров eps и n_samples. Сначала запустим алгоритм с параметрами по умолчанию(eps=0.5, min_samples=5)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQGhuBou9waI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbscan = DBSCAN()\n",
        "clusters = dbscan.fit_predict(X)\n",
        "print(\"Принадлежность к кластерам:\\n{}\".format(clusters))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA5dkVVeIvrH",
        "colab_type": "text"
      },
      "source": [
        "Мы видим, что всем точкам была присвоена метка -1, что означает \"шум\". Кластеры созданы не были. Причина этого - слишком маленькое eps и достаточно большое n_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve6rZnI2LS23",
        "colab_type": "text"
      },
      "source": [
        "Увеличим eps и уменьшим min_samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h0oTBKlLDAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbscan = DBSCAN(eps=3, min_samples=2)\n",
        "clusters = dbscan.fit_predict(X)\n",
        "print(\"Принадлежность к кластерам:\\n{}\".format(clusters))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOrAOcM6Lcau",
        "colab_type": "text"
      },
      "source": [
        "Теперь все точки объединились в один кластер с номером 0 (тоже не очень удачный вариант).\n",
        "Подберите параметры так, чтобы было выделено несколько кластеров"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-km0lmDzLDHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbscan = DBSCAN(eps=1, min_samples=3)\n",
        "clusters = dbscan.fit_predict(X)\n",
        "print(\"Принадлежность к кластерам:\\n{}\".format(clusters))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_6kjmyZT4cP",
        "colab_type": "text"
      },
      "source": [
        "Визуализируйте полученные данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3sItUZSUE-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(X[:,0], X[:,1], c=clusters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z4JvCfgLH4B",
        "colab_type": "text"
      },
      "source": [
        "#Основные шаги по выполнению лабораторной работы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgb-vSD-L5qx",
        "colab_type": "text"
      },
      "source": [
        "1. Импортируем необходимые библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6XbK-EQL2gZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams['figure.figsize']=(12,8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdpeQ7OHMlWz",
        "colab_type": "text"
      },
      "source": [
        "Воспользуемся библиотекой sklearn, чтобы сгенерировать \"игрушечные\" данные. Мы сгенерируем 200 объектов, имеющих 2 признака и разделенные на 5 кластеров. Кроме того, мы зададим значение random_state = 3 (цифра может быть любая), для повторяемости результатов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCeZJjVvMiqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "X,y = make_blobs(n_samples=100, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfkD2XL2NnG1",
        "colab_type": "text"
      },
      "source": [
        "Визуализируем данные, которые мы сгенерировали. Для визуализации в примере используется библиотека matplotlib. Можете использовать библиотеку plotly (как в прошлых лабораторных работах), которая строит интерактивные графики"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcur3NAKNelZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(X[:,0], X[:,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpz-M4s2S5la",
        "colab_type": "text"
      },
      "source": [
        "Воспользуемся библиотечным алгоритмом k-средних из библиотеки sklearn. Если вы не знаете (не помните) какие параметры можно задать при создании модели, после вызова имени функции вы можете нажать Shift+Tab (для google colab Alt+/), и вы получите справку по данной функции. Итак, для класса KMeans нам интересны следующие входные параметры: \n",
        "* n_clusters - количество кластеров, \n",
        "* init - способ инициализации центроидов (по умолчанию это значение 'k-means++', что нас устраивает), \n",
        "* n_init (по умолчанию=10) - этот параметр означает, что k-means будет инициализироваться 10 раз, и в конечном итоге будет выбрано то разбиение, которое имеет лучшее значение критерия k-means\n",
        "* random_state - нужен для повторяемости результатов. Если установить для этого параметра любое числовое значение (по умолчанию он None), то мы будем получать одинаковый результат при разных запусках, на разных ноутбуках и т.д.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqyV3rSMYU2Z",
        "colab_type": "text"
      },
      "source": [
        "Так как для реальных данных мы не знаем количество кластеров на которые оптимально разбить датасет, давайте для начала разобьем его на два кластера"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovv0GWdzN4Er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeansModel = KMeans(n_clusters=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd3_zkfpYlb4",
        "colab_type": "text"
      },
      "source": [
        "Обучим модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S64bZaePTWyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeansModel.fit(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtXzp79LYzVx",
        "colab_type": "text"
      },
      "source": [
        "После обучения мы можем получить метки кластеров, взяв атрибут класса KMeans под названием labels_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVUknko_Ys_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = kmeansModel.labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hptmxua2ZWBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkjOMkQmZi9c",
        "colab_type": "text"
      },
      "source": [
        "мы получили массив с метками классов соответствующих объектов (как мы и просили, классов у нас два: 0 и 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8GzCFOwZ9uA",
        "colab_type": "text"
      },
      "source": [
        "Визуализируем полученные результаты, добавив в функцию scatter массив с метками классов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrKJlj5eZcmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(X[:,0], X[:,1], c=labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuFozQqDadM8",
        "colab_type": "text"
      },
      "source": [
        "Деление на 2 кластера было пробным. Давайте попробуем подобрать более удачное количество кластеров с помощью метода локтя, который мы рассматривали в теоретической части лабораторной работы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvSvMLfka5At",
        "colab_type": "text"
      },
      "source": [
        "Вычислим значение критерия k-means для разных k и сохраним все эти значения в списке criteries. Сначала этот список пустой. Затем в цикле, где к меняется от 2 до 10, создаем модель для кластестеров с числом равным текущему значению k, обучаем ее, и добавляем вычисленный критерий (его берем как атрибут модели с именем inertia_) в наш список критериев"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84ljr8riZ2j2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criteries = []\n",
        "for k in range(2,10):\n",
        "  kmeansModel=KMeans(n_clusters=k, random_state=3)\n",
        "  kmeansModel.fit(X)\n",
        "  criteries.append(kmeansModel.inertia_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqEWL49SbvDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(criteries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqjThBSGczfB",
        "colab_type": "text"
      },
      "source": [
        "Для метода локтя мы должны построить график для полученных значений. По оси X у нас буду значения k, по оси у - вычисленные значения критерия"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lofpl8lcqug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(range(2,10), criteries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U475crBfdRJa",
        "colab_type": "text"
      },
      "source": [
        "как видно из графика, оптимальное количество кластеров в данном случае - 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvA-8sncdgJj",
        "colab_type": "text"
      },
      "source": [
        "Применим метод для 3 кластеров и посмотрим результат"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI1uer3TdJ6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeansModel=KMeans(n_clusters=3, random_state=0)\n",
        "kmeansModel.fit(X)\n",
        "labels = kmeansModel.labels_\n",
        "plt.scatter(X[:,0], X[:,1], c=labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PyFKb9Pr_dG",
        "colab_type": "text"
      },
      "source": [
        "а теперь сделаем кластеризацию с помощью метода DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuumJxXor-sO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "clustering = DBSCAN(eps=1, min_samples=5).fit_predict(X)\n",
        "print(clustering)\n",
        "plt.scatter(X[:,0], X[:,1], c=clustering);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JonqJexxvSq",
        "colab_type": "text"
      },
      "source": [
        "Подберем значения eps и min_sumples, чтобы получить результат как в методе k-means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jYW6AzE2gI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "clustering = DBSCAN(eps=1.75, min_samples=2).fit_predict(X)\n",
        "print(clustering)\n",
        "plt.scatter(X[:,0], X[:,1], c=clustering);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zv_L_U8eGod",
        "colab_type": "text"
      },
      "source": [
        "#Задание:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wei52dp29ma",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   Используйте метод K-средних и метод DBSCAN на самостоятельно сгенерированной выборке с количеством кластеров не менее 4. Для увеличения числа кластеров при генерации можно задать количество центров в функции make_blobs через параметр centers.\n",
        "2.   Используйте эти же два метода на датасете [Mall_Customers](https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python).\n",
        "3.   Для каждого метода необходимо построить график.\n"
      ]
    }
  ]
}