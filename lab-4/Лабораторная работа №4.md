# Лабораторная работа №4

Для первого пункта нам нужно создать свой датасет.

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
plt.style.use('ggplot')
plt.rcParams['figure.figsize']=(12,8)

from sklearn.datasets import make_blobs
X,y = make_blobs(n_samples=500, random_state=7, centers = 5)

plt.scatter(X[:,0], X[:,1])
```

![](https://i.imgur.com/YgeQ1LY.png)

Используя размер кластеров 2:

```python
from sklearn.cluster import KMeans
kmeansModel = KMeans(n_clusters=2) # мы пока не знаем количество кластеров
plt.scatter(X[:,0], X[:,1], c=kmeansModel.labels_) # визуализируем данные
```

Мы получим не совсем корректную кластеризацию, в том смысле, что, на самом деле, у нас больше кластеров, чем 2:

![]( https://i.imgur.com/1tbjud9.png) 

Мы разумеется, могли бы на глаз определить количество кластеров из графика, но лучше использовать более объективный метод, как метод Локтя:

```python
criteries = []
for k in range(2,10):
  kmeansModel=KMeans(n_clusters=k, random_state=7)
  kmeansModel.fit(X)
  criteries.append(kmeansModel.inertia_)
plt.plot(range(2,10), criteries)
```

![]( https://i.imgur.com/tIFtqF5.png) 

Как мы видим производная ближе к нулю сильнее с точки 5. Таким образом, оптимальное значение кластеров - это 5

Изменив параметры кластеризации, получим:

![](https://i.imgur.com/IZdOoJC.png)

Делаем тоже самое с **DBSCAN**:

```python
from sklearn.cluster import DBSCAN

clustering = DBSCAN(eps=1.55, min_samples=5).fit_predict(X)
print(clustering)
plt.scatter(X[:,0], X[:,1], c=clustering);
```

![](https://i.imgur.com/xAADB6Y.png)



## Работа с реальными данными

После тренировки на "игрушечных данных", нам предлагают пройти задания с реальными данными

Так как данные расположены во внешнем файле, то нам нужно его считать и сделать срезы

```python
import pandas as pd
from sklearn import preprocessing
X = pd.read_csv('data/Mall_Customers.csv').values  # считываем данные
```

```python
import matplotlib.pyplot as plt
%matplotlib inline
plt.style.use('ggplot')
plt.rcParams['figure.figsize']=(12,8)
data_1 = X[:,3]
data_2 = X[:,4]
plt.scatter(X[:,3], X[:,4])
```

![](https://i.imgur.com/F0ccJvr.png)

Метод Локтя:

![](https://i.imgur.com/Qw4bLEl.png)

```python
kmeansModel = KMeans(n_clusters=8) # используем k вычисленный через метод Локтя
kmeansModel.fit(X[:,3:4]) # обучаем модель
plt.scatter(X[:,3], X[:,4], c=kmeansModel.labels_) # визуализируем данные
```

![](https://i.imgur.com/msaMlUk.png)

```python
from sklearn.cluster import DBSCAN

clustering = DBSCAN(eps=2.8, min_samples=5).fit_predict(X[:,3:4])
plt.scatter(X[:,3], X[:,4], c=clustering);
```

![](https://i.imgur.com/7RMevIb.png)



### Authors

| [![Harsh Vijay](https://sun9-12.userapi.com/c856136/v856136536/d973c/TcuXKAIKNow.jpg?ava=1)](https://github.com/iharsh234) | <img src="https://sun9-9.userapi.com/c851436/v851436881/1de7b0/4SGaJjnz__k.jpg" width=110 height=180/> |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
|        [Arthur Kupriyanov](https://vk.com/apploidxxx)        |        [Artyom Kolokolov](https://vk.com/ifelseelif)         |

Группа: P3212

