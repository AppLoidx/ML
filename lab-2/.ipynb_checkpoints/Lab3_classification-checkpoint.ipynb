{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gtyGsN41cJfW"
   },
   "source": [
    "# Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6g3H7wUC7DuG"
   },
   "source": [
    "Обучение с учителем (обучение на размеченных данных) используется для решения двух основных типов задач: регрессия и классификация. Пример регрессии мы рассмотрели на прошлом занятии. В этой лабораторной работе рассмотрим классификацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rE28jnz73Oh7"
   },
   "source": [
    "##Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NC4Jqd9r8T3b"
   },
   "source": [
    "Простыми словами, классификация - это предсказание категории объекта. То есть, необходимо разделить объекты по заранее известному признаку: шарики по цветам, документы по языкам, музыку по жанрам.\n",
    "Примеры задач классификации:\n",
    "*   Спам-фильтры\n",
    "*   Определение языка\n",
    "*   Поиск похожих документов\n",
    "*   Анализ тональности\n",
    "*   Распознавание рукописных букв и цифр\n",
    "*   Определение подозрительных транзакций\n",
    "\n",
    "Задача классификации состоит в определении к какому классу из, как минимум, двух изначально известных относится данный объект. Обычно таким объектом является вектор в n-мерном вещественном пространстве $\\mathbb{R^n}$. Координаты вектора описывают отдельные аттрибуты объекта. Например, цвет c, заданный в модели RGB, является вектором в трехмерном пространстве: c=(red, green, blue).\n",
    "\n",
    "Математическая формулировка задачи классификации такова: пусть $X$ — пространство объектов (например, $\\mathbb{R^n}$), $Y$ — наши классы (например, $Y$ = {-1,1}). Дана обучающая выборка: $(x_1,y_1),..., (x_m,y_m)$. Требуется построить функцию $F : X\\rightarrow Y$ (классификатор), сопоставляющий класс $y$ произвольному объекту $x$.\n",
    "\n",
    "Если классов всего два («спам / не спам», «давать кредит / не давать кредит», «красное / черное»), то задача называется бинарной классификацией. Если классов несколько — многоклассовая (мультиклассовая) классификация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g05DAIS--zuh"
   },
   "source": [
    "Примеры алгоритмов, используемых для классификации: *Наивный Байес, Деревья Решений, Логистическая Регрессия, K-ближайших соседей, Метод Опорных Векторов*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xn0jzCJVMCv6"
   },
   "source": [
    "###Метод опорных векторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0q3ZWZGP8dck"
   },
   "source": [
    "Пожалуй, одним из самых популярным методом классификации является метод опорных векторов (Support Vector Machine — SVM). Данный метод изначально относится к бинарным классификаторам, хотя существуют способы заставить его работать и для задач мультиклассификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ArTXp8Y_BH4R"
   },
   "source": [
    "Идея SVM по своей сути проста: он ищет, как так провести две прямые между категориями, чтобы между ними образовался наибольший зазор. Проиллюстрируем это на простом примере: даны точки на плоскости, разбитые на два класса. Координаты точек - это два признака (для двумерного пространства, как в нашем случае). Например, для больного это уровень сахара в крови и индекс массы тела. Обучающая выборка разбита на 2 класса: диабетики (синие точки) и недиабетики(зеленые точки). Проведем линию, разделяющую эти два класса (красная линия). Далее, все новые точки (не из обучающей выборки) автоматически классифицируются следующим образом:\n",
    "\n",
    "* точка выше прямой попадает в класс A,\n",
    "* точка ниже прямой — в класс B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CmTYT173Bd7U"
   },
   "outputs": [],
   "source": [
    "#этот код - просто вставка картинки по ссылке\n",
    "from IPython.display import Image \n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://habrastorage.org/storage/habraeffect/8c/98/8c98d4824065028420f290d88e52b40e.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-ryfG8oKuZq"
   },
   "source": [
    "Такую прямую назовем разделяющей прямой. Однако, в пространствах высоких размерностей прямая уже не будет разделять наши классы, так как понятие «ниже прямой» или «выше прямой» теряет всякий смысл. Поэтому вместо прямых необходимо рассматривать гиперплоскости — пространства, размерность которых на единицу меньше, чем размерность исходного пространства. В $\\mathbb{R^3}$, например, гиперплоскость — это обычная двумерная плоскость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SL2m2zY6Kamn"
   },
   "source": [
    "В нашем примере существует несколько прямых, разделяющих два класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZkl7ZyJLA4f"
   },
   "outputs": [],
   "source": [
    "Image(url= \"https://habrastorage.org/storage/habraeffect/7c/5f/7c5f4284e204a7c4b544a9ca175a2b13.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFIXrEQoLF7V"
   },
   "source": [
    "С точки зрения точности классификации лучше всего выбрать прямую, расстояние от которой до каждого класса максимально. Другими словами, выберем ту прямую, которая разделяет классы наилучшим образом (красная прямая на рисунке выше). Такая прямая, а в общем случае — гиперплоскость, называется *оптимальной разделяющей гиперплоскостью*.\n",
    "\n",
    "Алгоритм SVM устроен таким образом, что он ищет точки на графике, которые расположены непосредственно к линии разделения ближе всего. Эти точки называются *опорными векторами*. Затем, алгоритм вычисляет расстояние между опорными векторами и разделяющей плоскостью. Это расстояние которое называется *зазором*. Основная цель алгоритма — **максимизировать расстояние зазора**. Лучшей гиперплоскостью считается такая гиперплоскость, для которой этот зазор является максимально большим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMYVafqoVv73"
   },
   "outputs": [],
   "source": [
    "Image(url= \"https://habrastorage.org/webt/ps/iy/he/psiyhexemtrhnqukbvmvaqzafvi.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Km5HjEapVfLQ"
   },
   "source": [
    "####Линейная неразделимость"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VRVsEIi-YEbo"
   },
   "source": [
    "На практике случаи, когда данные можно разделить гиперплоскостью, или, как еще говорят, линейно, довольно редки. Пример линейной неразделимости можно видеть на рисунке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "piv1NWADcyev"
   },
   "outputs": [],
   "source": [
    "Image(url= \"https://habrastorage.org/storage/habraeffect/3b/0a/3b0af1a82f51ee4b5fbbadf8b51d8fab.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RI2i8wneYEj-"
   },
   "source": [
    "В этом случае поступают так: все элементы обучающей выборки вкладываются в пространство $X$ более высокой размерности с помощью специального отображения $\\varphi:\\mathbb{R^n}\\rightarrow X$,использующую набор математических функций, известных как *ядра*. При этом отображение  выбирается так, чтобы в новом пространстве X выборка была линейно разделима."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ajjCQWWXeUEJ"
   },
   "source": [
    "Фактически мы добавляем еще одно измерение, чтобы разделить объекты, когда линейная разделимость невозможна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVcNVEXkYDEh"
   },
   "outputs": [],
   "source": [
    "Image(url= \"https://miro.medium.com/max/838/1*mCwnu5kXot6buL7jeIafqQ.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CT8JdEIHxuPi"
   },
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('3liCbRZPrZA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tq08bZ6dZHV2"
   },
   "source": [
    "####Реализация SVM c помощью библиотеки Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bgBPTSgfcf8h"
   },
   "source": [
    "В качестве примера рассмотрим задачу определения подлинности банкноты по 4 признакам, вычисленным по изображениям с помощью Wavelet Transforn tool. \n",
    "*   [Датасет](https://drive.google.com/file/d/13nw-uRXPY8XIZQxKRNZ3yYlho-CYm_Qt/view), \n",
    "*   [описание датасета](https://archive.ics.uci.edu/ml/datasets/banknote+authentication).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GtRGW6WhiiyR"
   },
   "source": [
    "Банкнота может быть подлинной или фальшивой. То есть, перед нами стоит задача бинарной классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pMzOyCLxjLpl"
   },
   "source": [
    "####Основные шаги:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "627mDc0SUunV"
   },
   "source": [
    "\n",
    "\n",
    "1.   Импортируем необходимые библиотеки\n",
    "2.   Скачиваем данные\n",
    "3.   Готовим данные, делим датасет на тренировочную и тестовую выборку\n",
    "4.   Обучаем модель\n",
    "5.   Предсказываем результат для тестовой выборки\n",
    "6.   Оцениваем модель\n",
    "7.   Делаем выводы\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1V-n3o3Tj_6K"
   },
   "source": [
    "#####1. Импортируйте необходимы библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAIXvWhjkI9j"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-3sPsMsUYf9G"
   },
   "source": [
    "#####2. Скачайте датасет, сохраните его локально на своем компьютере. \n",
    "Если вы работаете с google colabб сделайте upload этого файла в google colab. Прочитайте данные из csv-файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRrCR4Sjj1Hp"
   },
   "outputs": [],
   "source": [
    "bankdata = pd.read_csv(\"bill_authentication.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvlTwZGvD4TG"
   },
   "outputs": [],
   "source": [
    "bankdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCVI6MUvkluT"
   },
   "outputs": [],
   "source": [
    "bankdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fgw6vpeHkrMr"
   },
   "outputs": [],
   "source": [
    "bankdata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "58m7dk9sk2-1"
   },
   "source": [
    "Мы видим, что все признаки в наборе данных числовые. Целевая функция также числовая, то есть 0 и 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyL3ZjlUlOIN"
   },
   "source": [
    "#####3. Подготовьте данные\n",
    "Подготовка данных включает в себя:\n",
    "*    разделение данных на признаки (атрибуты) и целевую функцию (метку)\n",
    "*    разделение датасета на тренировочный и тестовый"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2jtAv9VElxxw"
   },
   "source": [
    "Чтобы разделить данные на признаки и целевую функцию, выполните следующий код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1dcpegTemBUW"
   },
   "outputs": [],
   "source": [
    "X = bankdata.drop('Class', axis=1)\n",
    "y = bankdata['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LyqTGjY7mPgV"
   },
   "source": [
    "Теперь все столбцы датасета, кроме столбца \"Class\", хранятся в переменной X - это наши признаки. Метки (столбец \"Class\") хранятся в переменной y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5TpXaKJOlVcE"
   },
   "source": [
    "Разделим датасет на тренировочную и тестовую выборку с помощью метода train_test_split из библиотеки Scikit-Learn (так же, как делали в прошлой лабораторной работе)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAeiAFETkvF6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JuHHJwnBnxVP"
   },
   "source": [
    "#####4. Обучите модель на тренировочных данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X30k2YGSoGPH"
   },
   "source": [
    "Scikit-Learn содержит **svm** библиотеку, которая включает в себя встроенные классы для различных алгоритмов SVM. Поскольку мы собираемся выполнить задачу классификации, мы будем использовать класс классификатора опорных векторов, который записан как SVC в svm библиотеке Scikit-Learn . Этот класс принимает один параметр, который является типом ядра. В случае простого SVM мы просто устанавливаем этот параметр как «линейный», поскольку простые SVM могут классифицировать только линейно разделимые данные. Нелинейные ядра в рамках данной лабораторной работы рассматривать не будем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cktmog-ennid"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sBLO6T-YpBTN"
   },
   "source": [
    "#####5. Предскажите результаты для тестовой выбоки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MmaP3_QXo0wh"
   },
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zk3VnyQOpLKc"
   },
   "outputs": [],
   "source": [
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hkLU39IQsiFe"
   },
   "outputs": [],
   "source": [
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xD-Pvleds8Gy"
   },
   "source": [
    "#####6. Оцените алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xoCg1scSsmTh"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgi5tp1NuehR"
   },
   "source": [
    "Давайте посмотрим, какие метрики можно использовать в задачах классификации и как по ним оценить качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_a8YgklQu66I"
   },
   "source": [
    "6.1 Матрица ошибок (Confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jT7BQMQevGHR"
   },
   "source": [
    "Допустим, что у нас есть два класса и алгоритм, предсказывающий принадлежность каждого объекта одному из классов, тогда матрица ошибок классификации будет выглядеть следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hzxrmj4Xyr7V"
   },
   "outputs": [],
   "source": [
    "Image(url= \"https://glassboxmedicine.files.wordpress.com/2019/02/confusion-matrix.png?w=816\", width=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iD6Aziaa0UaA"
   },
   "source": [
    "Таким образом, ошибки классификации бывают двух видов: False Negative (FNs) и False Positive (FPs). False Positive - это ложное срабатывание. То есть, банкнота подлинная, но мы классифицировали ее как фальшивую. False Negative - неопознанная фальшивка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8ox1In12wlT"
   },
   "source": [
    "6.2 Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XORF0NpO3BoU"
   },
   "source": [
    "Интуитивно понятной, очевидной и почти неиспользуемой метрикой является accuracy — доля правильных ответов алгоритма:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UTkRe2qJ3Bw7"
   },
   "source": [
    "$$\\large accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nC3WEnRO3P08"
   },
   "source": [
    "Эта метрика бесполезна в задачах с неравными классами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKCj4Mt_4jRc"
   },
   "source": [
    "6.3 Precision, recall и F-мера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6dPjVgmi4or-"
   },
   "source": [
    "Для оценки качества работы алгоритма на каждом из классов по отдельности введем метрики precision (точность) и recall (полнота)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g3PhLZUF4rzE"
   },
   "source": [
    "$$\\large precision = \\frac{TP}{TP + FP}$$ $$\\large recall = \\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5A-WJT65JG1"
   },
   "source": [
    "Precision можно интерпретировать как долю объектов, названных классификатором положительными и при этом действительно являющимися положительными, а recall показывает, какую долю объектов положительного класса из всех объектов положительного класса нашел алгоритм.\n",
    "Recall демонстрирует способность алгоритма обнаруживать данный класс вообще, а precision — способность отличать этот класс от других классов.\n",
    "\n",
    "Понятно что чем выше точность и полнота, тем лучше. Но в реальной жизни максимальная точность и полнота не достижимы одновременно и приходится искать некий баланс. Поэтому, хотелось бы иметь некую метрику которая объединяла бы в себе информацию о точности и полноте нашего алгоритма. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uaTAkQ9y5iVV"
   },
   "source": [
    "Существует несколько различных способов объединить precision и recall в агрегированный критерий качества. F-мера (в общем случае $F_{\\beta}$) — среднее гармоническое precision и recall :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rJ2er6er5sR-"
   },
   "source": [
    "$$\\large \\ F_\\beta = (1 + \\beta^2) \\cdot \\frac{precision \\cdot recall}{(\\beta^2 \\cdot precision) + recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCNK-FSo7MDv"
   },
   "source": [
    "где β принимает значения в диапазоне 0<β<1 если вы хотите отдать приоритет точности, а при β>1 приоритет отдается полноте. При β=1 получим среднее гармоническое между точностью и полнотой"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9Nnzijj6ksG"
   },
   "source": [
    "F-мера достигает максимума при полноте и точности, равными единице, и близка к нулю, если один из аргументов близок к нулю."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HTejF8nIAgta"
   },
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BLg5OyyNootd"
   },
   "source": [
    "Вторым, рассматриваемым в этой лабораторной, методом является Дерево решений. Решение, в какой класс причислить объект, программа принимает на основе множества вопросов, ответами на которые является \"да\" или \"нет\". \n",
    "\n",
    "Структура дерева представляет собой «листья» и «ветки». На рёбрах («ветках») дерева решения записаны атрибуты, от которых зависит целевая функция, в «листьях» записаны значения целевой функции, а в остальных узлах — атрибуты, по которым различаются случаи. Чтобы классифицировать новый случай, надо спуститься по дереву до листа и выдать соответствующее значение.\n",
    "\n",
    "Деревья разделяются на уровни, и, чем выше уровень, тем более общий должен быть вопрос.\n",
    "\n",
    "В реальной жизни чаще всего используется не одно Дерево решений, а так называемый алгоритм Случайного леса (random forest).\n",
    "\n",
    "Возьмем для примера ситуацию в банке, когда необходимо принять решение о выдаче кредита. Начало дерева решений может иметь подобный вид:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKXfZRDMsAHs"
   },
   "outputs": [],
   "source": [
    "Image(url= \"https://hsto.org/files/194/9b6/ae9/1949b6ae97ab4fc9b1a37fbf182eda8f.gif\", width=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-dJKwTDnuslT"
   },
   "source": [
    "На основе этого дерева 40-летнему мужчине, у которого есть дом, будет выдан кредит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pRPmbKz-62u3"
   },
   "source": [
    "Для обучения модели достаточно \"скормить\" ей тренировочные данные, а необходимые вопросы будут подобраны автоматически. При обучении модели будет введен примесь(критерий) Джинни (Gini) или Загрязнение Джини (! не путать с коэффициентом Джинни). Это величина, которую дерево решений стремится минимизировать при разделении каждого узла. Представляет возможность того, что случайно выбранный образец будет неверно классифицирован в определённом узле."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kSMWJiD38e8X"
   },
   "source": [
    "$$Gini(n) = 1-\\sum_{i=1}^J{p_i^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QeCGYLV_9_Sg"
   },
   "source": [
    "где n - это номер узла,\n",
    "    J - количество классов,\n",
    "    p_i - количество образцов(данных),\n",
    "    i - номер образца."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W797bLGsAin4"
   },
   "source": [
    "При рассмотрении этого метода мы рассмотрим важный параметр в машинном обучении как Переобучение. Простыми словами это когда построенная модель хорошо работает на примерах из обучающей выборки, но  плохо работает на примерах из тестовой выборки. Получается, что модель подстроилась не только под важные закономерности в данных, но и под существующих в них шум. Дерево решений относится к тому методу, который с высокой вероятноятью без ограничений даст переобучение модели.\n",
    "\n",
    "Алгоритм дерева решений часто  переобучается, если не ограничить его максимальную глубину или не использовать несколько деревьев (случайный лес). Дерево решений обладает неограниченной гибкостью и может разрастаться, пока не достигнет состояния идеальной классификации, в которой каждому образцу из набора данных будет соответствовать один лист."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dHYPH5e3AnV7"
   },
   "source": [
    "Возвращаясь к нашему датасету, попробуем применить Дерево решений для определения подлинности банкноты. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3kP8LNOMwfwh"
   },
   "source": [
    "#####4. Обучите модель на тренировочных данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4DjZKi2Kwq-D"
   },
   "source": [
    "Scikit-Learn содержит tree библиотеку, которая включает в себя встроенные классы для различных алгоритмов построения деревьев. Мы будем использовать алгоритм CART (Classification And Regression Tree), который записан как DecisionTreeClassifier в tree библиотеке Scikit-Learn без дополнительных параметров. Основные параметры этого класса:\n",
    "\n",
    "\n",
    "*   max_depth – максимальная глубина дерева\n",
    "*   max_features — максимальное число признаков, по которым ищется лучшее разбиение в дереве\n",
    "*   min_samples_leaf – минимальное число объектов в листе.\n",
    "\n",
    "Однако для данной задачи мы их ограничивать не будем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CCb6oocZ4pyM"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "TreeClassifier = DecisionTreeClassifier()\n",
    "TreeClassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VXY3ntOJyQ0U"
   },
   "source": [
    "#####5. Предскажите результаты для тестовой выбоки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Go9E4yBlA9So"
   },
   "outputs": [],
   "source": [
    "yTree_pred = TreeClassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0kXt9Sddyd2l"
   },
   "outputs": [],
   "source": [
    "print(yTree_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2zGKjJxyd2o"
   },
   "outputs": [],
   "source": [
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QPiBd7ARyZLD"
   },
   "source": [
    "#####6. Оцените алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAW_xj9qBAEm"
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, yTree_pred))\n",
    "print(classification_report(y_test, yTree_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jHKaKMqryrtl"
   },
   "source": [
    "При использовании Деревьев решений хорошим способом оценить результат является построение визуализированного дерева на основе обучения. \n",
    "\n",
    "Для этого выделим столбцы нашего датасета и построим на их основе Дерево."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "akDp9L_kSl8t"
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_RdkDwLBDR_"
   },
   "outputs": [],
   "source": [
    "# используем .dot формат для визуализации дерева\n",
    "from sklearn.tree import export_graphviz\n",
    "# в feature_names можно прямо прописать названия признаков, а можно написать X_train.columns\n",
    "export_graphviz(TreeClassifier, feature_names=['Variance', 'Skewness', 'Curtosis', 'Entropy'], class_names=['0', '1'], \n",
    "out_file='small_tree.dot', filled=True)\n",
    "# для этого понадобится библиотека pydot (pip install pydot)\n",
    "!dot -Tpng 'small_tree.dot' -o 'small_tree.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MWRXiBKdDZEs"
   },
   "source": [
    "Во всех узлах, кроме листьев (цветные узлы без исходящих связей), содержится 5 частей:\n",
    "1. Вопрос о значении параметра образца. Ответ может принимать значение True или False. Это точка разделения узла, в зависимости от ответа определяется, в каком направлении вниз по дереву продвинется образец данных.\n",
    "2.  Gini: средневзвешенное загрязнение Джини должно уменьшаться по мере того, как мы движемся вниз по дереву.\n",
    "3.  Samples: количество прошедших через этот узел образцов.\n",
    "4.  Value: отношение классов, прошедших через этот узел, выраженное в абсолютных числах. К примеру, верхний узел выделил 605 образцов класса 0 и 492 образца класса 1.\n",
    "5. Class: класс большинства прошедших через узел образцов. Для листьев это прогнозируемое значение всех попадающих в эти узлы элементов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uMJxDGqjSaid"
   },
   "outputs": [],
   "source": [
    "Image(\"small_tree.png\", width=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wLo3EqzR_92K"
   },
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2BFnJBiAOif"
   },
   "source": [
    "1. Возьмите датасет [Heart Disease](https://www.kaggle.com/ronitf/heart-disease-uci/) или [Pulsar Star](https://www.kaggle.com/pavanraj159/predicting-a-pulsar-star/) и сравните результаты применения метода опорных векторов и метода деревьев на выбранном датасете.\n",
    "2. При применении метода деревьев обучите классификатор дважды: без ограничений и с ограничениями одного или нескольких основных параметров.\n",
    "3. Постройте визуализацию дерева."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab3_classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
